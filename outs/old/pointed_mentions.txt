List of scored Method/Technologies
-----------------------------------

['BLEU', 4.600000000000001]
['SMT', 4.600000000000001]
[['suggestive', 'evidence'], 4.4]
[['human', 'mind'], 4.4]
[['frequent', 'phenomenon'], 4.4]
[['additional', 'difficulty'], 4.4]
[['following', 'contribution'], 4.4]
[['significant', 'improvement'], 4.4]
['IBM', 4.000000000000001]
['English', 3.400000000000001]
['CWS', 3.400000000000001]
[['significant', 'gain'], 3.0]
[['good', 'association', 'measure'], 3.0]
[['algorithmic', 'handle', 'provide'], 3.0]
[['model', 'search'], 3.0]
[['dynamic', 'cache'], 3.0]
[['cache-based', 'approach'], 3.0]
[['unsupervised', 'way', 'use', 'topic', 'model'], 3.0]
[['statistical', 'translation'], 3.0]
[['low', 'frequency'], 3.0]
[['underlying', 'latent', 'topic'], 3.0]
[['unsupervised', 'domain'], 3.0]
[['word', 'pair'], 3.0]
[['adapted'], 3.0]
[['new', 'approach'], 3.0]
[['low', 'F-score'], 3.0]
[['selective', 'use'], 3.0]
[['new', 'notion'], 3.0]
[['Viterbi', 'alignment'], 3.0]
[['Gibbs', 'sampler'], 3.0]
['language pair', 2.1999999999999997]
['Morin', 2.1999999999999997]
['Hillary Clinton', 1.9999999999999998]
['LSA', 1.9999999999999998]
['word alignment', 1.9999999999999998]
['HMM', 1.9999999999999998]
['USA', 1.9999999999999998]
['Annual Meeting', 1.9999999999999998]
['CRF', 1.9999999999999998]
['OOV', 1.9999999999999998]
['machine translation', 1.9999999999999998]
['Ney', 1.9999999999999998]
['TSP', 1.9999999999999998]
['Models 1-2', 1.7999999999999998]
['Tsujii', 1.7999999999999998]
['syntactic information', 1.7999999999999998]
['generative model', 1.7999999999999998]
['suggestive evidence', 1.7999999999999998]
['word embeddings', 1.7999999999999998]
['correct sense', 1.7999999999999998]
['cross-lingual Word Sense Disambiguation', 1.7999999999999998]
['WSD', 1.7999999999999998]
['Word Sense Induction', 1.7999999999999998]
['WSI', 1.7999999999999998]
['SgVerb', 1.7999999999999998]
['good selection', 1.7999999999999998]
['Comparative', 1.7999999999999998]
['system show', 1.7999999999999998]
['TREC', 1.7999999999999998]
['translation model', 1.7999999999999998]
['Empirical', 1.7999999999999998]
['Language Processing', 1.7999999999999998]
['word perplexity', 1.7999999999999998]
['Republic', 1.7999999999999998]
['Machine Translation', 1.7999999999999998]
['word segmentation', 1.7999999999999998]
['Experimental', 1.7999999999999998]
['cross-lingual', 1.7999999999999998]
['speech recognition', 1.7999999999999998]
['language model', 1.7999999999999998]
['Bayesian', 1.7999999999999998]
['Waibel', 1.7999999999999998]
['suboptimal solution', 1.7999999999999998]
[['log-linear', 'combination'], 1.6]
[['sense', 'cluster'], 1.6]
[['related', 'work'], 1.6]
[['famous', 'female', 'leader'], 1.6]
[['such', 'algorithm'], 1.6]
[['approximative', 'algorithm'], 1.6]
[['narrow', 'verbal', 'paradigm'], 1.6]
[['initial', 'sentence'], 1.6]
[['receive', 'increase', 'attention'], 1.6]
[['standard', 'technique'], 1.6]
[['incorporate', 'lexical', 'weighting', 'feature', 'condition'], 1.6]
[['acquirement', 'ability'], 1.6]
[['arbitrary', 'objective', 'function'], 1.6]
[['topic', 'model'], 1.6]
[['T-component', 'mixture'], 1.6]
[['graph', 'alignment', 'algorithm'], 1.6]
[['bLSA', 'framework'], 1.6]
[['multiple', 'translation', 'model', 'generate'], 1.6]
[['equivalence', 'class'], 1.6]
[['name-aware', 'framework'], 1.6]
[['critical', 'information'], 1.6]
[['novel', 'Name-aware'], 1.6]
[['best', 'result'], 1.6]
[['+1.04', 'BLEU', 'average', 'improvement'], 1.6]
[['Verbmobil', 'project'], 1.6]
[['good', 'correlation', 'betweenG1', 'decode'], 1.6]
[['multi-stack', 'decoder'], 1.6]
[['good', 'performance'], 1.6]
[['bilingual', 'word', 'embeddings'], 1.6]
[['bigram', 'model'], 1.6]
[['cosine', 'similarity', 'measure'], 1.6]
[['pattern', 'match', 'approach'], 1.6]
[['projection-based', 'approach'], 1.6]
[['Shared', 'Translation', 'Task'], 1.6]
[['POS-based', 'reordering'], 1.6]
[['Gibbs', 'sampling-based', 'Bayesian', 'inference', 'method'], 1.6]
[['Bayesian', 'inference', 'outperforms'], 1.6]
[['sparse', 'Dirichlet'], 1.6]
[['algorithmic', 'framework'], 1.6]
[['mathematical', 'formulation'], 1.6]
[['restrict', 'stack-based', 'search'], 1.6]
[['Held-Karp', 'dynamic', 'programming', 'algorithm'], 1.6]
[['exponential', 'time', 'algorithm'], 1.6]
[['few', 'illustration'], 1.6]
['Since', 1.5999999999999999]
['good association measure', 1.5999999999999999]
['EPILOG', 1.5999999999999999]
['Hwang', 1.5999999999999999]
['Bos', 1.5999999999999999]
['drop modifier', 1.5999999999999999]
['Bilingual Evaluation', 1.5999999999999999]
['word equally', 1.5999999999999999]
['3percent', 1.5999999999999999]
['Retrieval Evaluation', 1.5999999999999999]
['supervise learning', 1.5999999999999999]
['Ranking SVM', 1.5999999999999999]
['good translation', 1.5999999999999999]
['Topic', 1.5999999999999999]
['Bilingual', 1.5999999999999999]
['BiTAM', 1.5999999999999999]
['topic model', 1.5999999999999999]
['Simple', 1.5999999999999999]
['word surround', 1.5999999999999999]
['word pair', 1.5999999999999999]
['Syntactic', 1.5999999999999999]
['syntactic constituent', 1.5999999999999999]
['sentence Semantic information', 1.5999999999999999]
['WordNet', 1.5999999999999999]
['language modeling', 1.5999999999999999]
['Rosenfeld', 1.5999999999999999]
['Klakow', 1.5999999999999999]
['Edinburgh', 1.5999999999999999]
['level translation', 1.5999999999999999]
['BLUE', 1.5999999999999999]
['European language', 1.5999999999999999]
['E-step', 1.5999999999999999]
['dynamic-programming', 1.5999999999999999]
['mixture extension', 1.5999999999999999]
['specific dynamicprogramming decode algorithm', 1.5999999999999999]
['baseline model', 1.5999999999999999]
['component mixture', 1.5999999999999999]
['Renlifang GcAbstracting translation', 1.5999999999999999]
['graph mapping Figure', 1.5999999999999999]
['Jli', 1.5999999999999999]
['Engkoo3', 1.5999999999999999]
['Microsoft Research Asia', 1.5999999999999999]
['MIT', 1.5999999999999999]
['9-11 October', 1.5999999999999999]
['Microsoft Research', 1.5999999999999999]
['Melinda', 1.5999999999999999]
['Latent Dirichlet-Tree', 1.5999999999999999]
['LDTA', 1.5999999999999999]
['bLSA', 1.5999999999999999]
['text translation', 1.5999999999999999]
['multiple translation model', 1.5999999999999999]
['significant difference between', 1.5999999999999999]
['ACL', 1.5999999999999999]
['represent', 1.5999999999999999]
['grammar extraction', 1.5999999999999999]
['name-aware', 1.5999999999999999]
['training', 1.5999999999999999]
['McNamee', 1.5999999999999999]
['McKeown', 1.5999999999999999]
['word include', 1.5999999999999999]
['English-to-Arabic translation', 1.5999999999999999]
['simple English sentence', 1.5999999999999999]
['Koehn', 1.5999999999999999]
['Verbmobil', 1.5999999999999999]
['62percent', 1.5999999999999999]
['Bayes', 1.5999999999999999]
['good correlation', 1.5999999999999999]
['decode anddecoding', 1.5999999999999999]
['word consider', 1.5999999999999999]
['INSERT', 1.5999999999999999]
['TIDES', 1.5999999999999999]
['CPU', 1.5999999999999999]
['fast', 1.5999999999999999]
['sacrifice translation', 1.5999999999999999]
['Waibel report', 1.5999999999999999]
['sentence feasible', 1.5999999999999999]
['restricted version', 1.5999999999999999]
['multi-stack', 1.5999999999999999]
['SER', 1.5999999999999999]
['6-word sentence', 1.5999999999999999]
['8-word sentence', 1.5999999999999999]
['greedy decoding', 1.5999999999999999]
['Jamaican', 1.5999999999999999]
['Early', 1.5999999999999999]
['phonetic feature', 1.5999999999999999]
['phonetic similarity', 1.5999999999999999]
['Khudanpur', 1.5999999999999999]
['Langlais', 1.5999999999999999]
['English-Chinese CrossLanguage Information Retrieval', 1.5999999999999999]
['CLIR', 1.5999999999999999]
['Retrieval', 1.5999999999999999]
['show good', 1.5999999999999999]
['NIST08 Chinese-English', 1.5999999999999999]
['Stanford Phrasal', 1.5999999999999999]
['semantic similarity', 1.5999999999999999]
['bilingual embeddings', 1.5999999999999999]
['NIST08', 1.5999999999999999]
['Exact', 1.5999999999999999]
['probable translation', 1.5999999999999999]
['NP-Hard', 1.5999999999999999]
['domain making', 1.5999999999999999]
['context give moreLO', 1.5999999999999999]
['Zweigenbaum', 1.5999999999999999]
['word term', 1.5999999999999999]
['International Conference', 1.5999999999999999]
['multi-word', 1.5999999999999999]
['sentence context', 1.5999999999999999]
['word Dejean', 1.5999999999999999]
['Shared Translation', 1.5999999999999999]
['submit translation', 1.5999999999999999]
['EnglishFrench', 1.5999999999999999]
['POS', 1.5999999999999999]
['short-range reordering', 1.5999999999999999]
['WMT', 1.5999999999999999]
['English-German', 1.5999999999999999]
['Gibbs sampling-based Bayesian', 1.5999999999999999]
['GIZA', 1.5999999999999999]
['word position', 1.5999999999999999]
['sparse Dirichlet', 1.5999999999999999]
['NLP', 1.5999999999999999]
['Griffiths', 1.5999999999999999]
['Gibbs', 1.5999999999999999]
['Bayesian setting', 1.5999999999999999]
['random variable', 1.5999999999999999]
['suitable prior', 1.5999999999999999]
['NPhard', 1.5999999999999999]
['Kevin Knight show', 1.5999999999999999]
['HeldKarp', 1.5999999999999999]
['Since optimal', 1.5999999999999999]
['fast suboptimal search', 1.5999999999999999]
['word long', 1.5999999999999999]
['simple computing', 1.5999999999999999]
['Scores7 Logscoresmada', 1.5999999999999999]
