<html>
    <head>
      <style type="text/css">

        p {
          font-size: 14px;
        }
        .column {
            float: left;
            width: 50%;
            padding:0%;
            margin:0%;

        }
        .subcolumn {
            float: left;
            width: 30%;
            padding:0%;
            margin:0%;

        }

        .row {
          width:100%;
          padding:0%;
          margin:0%;

        }

        img {

          max-width: 96%;
        }

        .row:after {
            content: "";
            display: table;
            clear: both;
        }
        .collapsible {
          background-color: #66ccff;
          color: #444;
          cursor: pointer;
          padding: 18px;
          width: 100%;
          border: none;
          text-align: left;
          outline: none;
          font-size: 15px;
        }

        .active, .collapsible:hover {
          background-color: #ccc;
        }

        .content {
          padding:1% !important;
          padding: 0 18px;
          display: none;
          overflow: hidden;
          background-color: #f1f1f1;
          max-width: 100%;
          margin:0%;

        }

        #subcollapsible {
          background-color: #4bab81 !important;

        }

        #subsubcollapsible {
          background-color: #81a118 !important;

        }
      </style>
    </head>
    <body>

      <button type="button" class="collapsible">Results for the query (QUERY)</button>
      <div class="content">
        <div class="row">
          <div class="column" name="paper_titles">
							<p> (1) - ﻿Semantic Role Features for Machine Translation
							</p>
							<p> (2) - ﻿Computational Complexity of Statistical Machine  Translation
							</p>
							<p> (3) - ﻿An Algorithmic Framework for the Decoding Problem in
 Statistical Machine Translation
							</p>
							<p> (4) - ﻿Greedy Decoding for Statistical Machine Translation in Almost Linear Time
							</p>
							<p> (5) - ﻿Refined Lexicon Models for Statistical Machine Translation using a
 Maximum Entropy Approach
							</p>
							<p> (6) - ﻿Toward hierarchical models for statistical machine translation of
 inflected languages
 							</p>
							<p> (7) - ﻿The RWTH System for Statistical Translation of Spoken
 Dialogues
							</p>
							<p> (8) - ﻿Enriching Entity Translation  Discovery using Selective Temporality
							</p>
							<p> (9) - ﻿Fusion of Multiple Features and Ranking SVM for
 Web-based English-Chinese OOV Term Translation
							</p>
							<p> (10) - ﻿Mining Name Translations from Entity Graph Mapping∗
							</p>
							<p> (11) - ﻿Cross-lingual WSD for Translation Extraction
 from Comparable Corpora
 							</p>
							<p> (12) - ﻿Name-aware Machine Translation

 Haibo Li†	Jing Zheng‡	Heng Ji†	Qi Li†	Wen Wang‡
							</p>
							<p> (13) - ﻿Revisiting Context-based Projection Methods for
 Term-Translation Spotting in Comparable Corpora
							</p>
							<p> (14) - ﻿
 NICT-ATR Speech-to-Speech Translation System
							</p>
							<p> (15) - ﻿Improved Statistical Machine Translation by Multiple Chinese Word
 Segmentation
							</p>
							<p> (16) - ﻿Bayesian Word Alignment for Statistical Machine Translation
							</p>
							<p> (17) - ﻿Topic Models for Dynamic Translation Model Adaptation
							</p>
							<p> (18) - ﻿Domain Adaptation in Statistical Machine Translation with Mixture
 Modelling ∗
							</p>
							<p> (19) - ﻿Cache-based Document-level Statistical Machine Translation
							</p>
							<p> (20) - ﻿Bilingual-LSA Based LM Adaptation for Spoken Language Translation
							</p>
							<p> (21) - ﻿Bilingual Word Embeddings for Phrase-Based Machine Translation
							</p>
							<p> (22) - ﻿Japanese Named Entity Recognition
 Using Structural Natural Language Processing
							</p>
							<p> (23) - ﻿The Karlsruhe Institute of Technology Translation Systems
 for the WMT 2011
							</p>
							<p> (24) - ﻿Non-parametric Bayesian Segmentation of Japanese Noun Phrases
							</p>
							<p> (25) - ﻿A Class-Based Agreement Model for
 Generating Accurately Inflected Translations
							</p>
</div>
          <div class="column">
            <button type="button" class="collapsible">Technology Methods</button>
            <div class="content" name="mentions">
              <div class="row">
                <div class="subcolumn" name="left-mentions">							<p> BLEU							</p>
							<p>  							</p>
							<p>  human mind							</p>
							<p>  							</p>
							<p>  following contribution							</p>
							<p>  							</p>
							<p> English							</p>
							<p>  							</p>
							<p>  good association measure							</p>
							<p>  							</p>
							<p>  dynamic cache							</p>
							<p>  							</p>
							<p>  statistical translation							</p>
							<p>  							</p>
							<p>  unsupervised domain							</p>
							<p>  							</p>
							<p>  low F-score							</p>
							<p>  							</p>
							<p>  non-parametric Bayesian language model							</p>
							<p>  							</p>
							<p> language pair							</p>
							<p>  							</p>
							<p> Hillary Clinton							</p>
							<p>  							</p>
							<p> HMM							</p>
							<p>  							</p>
							<p> CRF							</p>
							<p>  							</p>
							<p> Ney							</p>
							<p>  							</p>
							<p> Tsujii							</p>
							<p>  							</p>
							<p> suggestive evidence							</p>
							<p>  							</p>
							<p> cross-lingual Word Sense Disambiguation							</p>
							<p>  							</p>
							<p> WSI							</p>
							<p>  							</p>
							<p> Comparative							</p>
							<p>  							</p>
							<p> Edinburgh							</p>
							<p>  							</p>
							<p> Language Processing							</p>
							<p>  							</p>
							<p> Machine Translation							</p>
							<p>  							</p>
							<p> cross-lingual							</p>
							<p>  							</p>
							<p> Bayesian							</p>
							<p>  							</p>
</div>
                <div class="subcolumn" name="center-mentions">							<p> SMT							</p>
							<p>  							</p>
							<p>  frequent phenomenon							</p>
							<p>  							</p>
							<p>  significant improvement							</p>
							<p>  							</p>
							<p> CWS							</p>
							<p>  							</p>
							<p>  algorithmic handle provide							</p>
							<p>  							</p>
							<p>  cache-based approach							</p>
							<p>  							</p>
							<p>  low frequency							</p>
							<p>  							</p>
							<p>  word pair							</p>
							<p>  							</p>
							<p>  selective use							</p>
							<p>  							</p>
							<p>  Viterbi alignment							</p>
							<p>  							</p>
							<p> Morin							</p>
							<p>  							</p>
							<p> LSA							</p>
							<p>  							</p>
							<p> USA							</p>
							<p>  							</p>
							<p> OOV							</p>
							<p>  							</p>
							<p> TSP							</p>
							<p>  							</p>
							<p> syntactic information							</p>
							<p>  							</p>
							<p> word embeddings							</p>
							<p>  							</p>
							<p> WSD							</p>
							<p>  							</p>
							<p> SgVerb							</p>
							<p>  							</p>
							<p> system show							</p>
							<p>  							</p>
							<p> translation model							</p>
							<p>  							</p>
							<p> word perplexity							</p>
							<p>  							</p>
							<p> word segmentation							</p>
							<p>  							</p>
							<p> speech recognition							</p>
							<p>  							</p>
							<p> Waibel							</p>
							<p>  							</p>
</div>
                <div class="subcolumn" name="right-mentions">							<p>  suggestive evidence							</p>
							<p>  							</p>
							<p>  additional difficulty							</p>
							<p>  							</p>
							<p> IBM							</p>
							<p>  							</p>
							<p>  significant gain							</p>
							<p>  							</p>
							<p>  model search							</p>
							<p>  							</p>
							<p>  propose method							</p>
							<p>  							</p>
							<p>  underlying latent topic							</p>
							<p>  							</p>
							<p>  adapted							</p>
							<p>  							</p>
							<p>  nonparametric Bayesian language model							</p>
							<p>  							</p>
							<p>  Gibbs sampler							</p>
							<p>  							</p>
							<p> NER							</p>
							<p>  							</p>
							<p> word alignment							</p>
							<p>  							</p>
							<p> Annual Meeting							</p>
							<p>  							</p>
							<p> machine translation							</p>
							<p>  							</p>
							<p> Models 1-2							</p>
							<p>  							</p>
							<p> generative model							</p>
							<p>  							</p>
							<p> correct sense							</p>
							<p>  							</p>
							<p> Word Sense Induction							</p>
							<p>  							</p>
							<p> good selection							</p>
							<p>  							</p>
							<p> TREC							</p>
							<p>  							</p>
							<p> Empirical							</p>
							<p>  							</p>
							<p> Republic							</p>
							<p>  							</p>
							<p> Experimental							</p>
							<p>  							</p>
							<p> language model							</p>
							<p>  							</p>
							<p> suboptimal solution							</p>
							<p>  							</p>
</div>
              </div>
            </div>
          </div>
          <div class="row">
                <div class="column">
                </div>
                <div class="column">
                  <!--<div id="button"><a href="./ldavis_prepared_11.html">See the LDA</a></div> -->
                </div>
          </div>
          <div class="row">
              <button type="button" class="collapsible">Mentions per paper</button>
              <div class="content" name="papers-mentions">								<button type="button" class="collapsible"> 25 </button>
									<div class="content"> 
										<p>BLEU, SMT, English,  model search,  adapted, language pair, LSA, word alignment, Annual Meeting, machine translation, translation model, word perplexity, Republic, speech recognition, language model, Bayesian, </p> 
									</div> 
</div>
          </div>
          <div class="row">
              <button type="button" class="collapsible">ScatterPlot of Methods (TSNE)</button>
              <div class="content" name="stats2">
                <div class="column">
                  <img src="./men_bigrams.png" alt="plot" width="1000" height="1000">
                </div>
                <div class="column">
                  <img src="./men_trigrams.png" alt="plot" width="1000" height="1000">
                </div>
              </div>
          </div>
        </div>
      </div>

      <button type="button"  class="collapsible">Claims</button>
      <div class="content">
        <button type="button" id="subcollapsible" class="collapsible">Cluster of Claims (Bigrams)</button>
        <div class="content">
          <div class="row">
            <div class="column">
                <img src="./claims_bigrams.png" alt="plot" width="1000" height="1000">
            </div>
            <div class="column" name="bigram_claims">
							<p> 
							</p>
							<p>  							</p>
						<button type="button" id="subsubcollapsible" class="collapsible">Sentences in cluster n0</button>
						<div class="content">
							<p> 	We believe that by performing a rescoring on translation word graphs we will obtain a more significant improvement in translation quality .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We prove that while IBM Models 1-2 are conceptually and computationally simple , computations involving the higher ( and more useful ) models are hard.Since it is unlikely that there exists a poly-language 1 ( Tillman , 2001 Wang , 1997 Germann et al 2003 Udupa et al 2004 The models are independent of the language pair and therefore , can be used to build a translation system for any language pair as long as a parallel corpus of texts is available for training .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	One latent outcome of this work is that Wikipedia is surprisingly suitable for mining medical terms .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	A closer look at the translation candidates obtained when using LL , the most popular association measure in projection-based approaches , shows that they are often collocates of the reference translation .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	One interesting outcome of this study is that significant gains can be obtained by using an association measure that is rarely used in practice .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We plan to check its adequacy for other domains and verify that LO remains a better association measure for different corpora and domains
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Still , it is already striking that a direct comparison of them is difficult , if not impossible .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Further , our results offer suggestive evidence that bilingual word embeddings act as high-quality semantic features and embody bilingual translation equivalence across languages .6 We report case-insensitive BLEU7 With 4-gram BLEU metric from .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Nevertheless , they found that human mind is very well capable of deriving dependencies such as morphology , cognates , proper names , spelling variations etc and that this capability was finally at the basis of the better results produced by humans compared to corpus based machine translation .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	As there is a large overlap between the modeled events in the combined probabilistic models , we assume that log-linear combination would result in more improvement of the translation quality than the combination by linear interpolation does .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We believe that decoding algorithms derived from our framework can be of practical significance .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	The results show that data-driven semantic analysis can help to circumvent the need for an external seed dictionary , traditionally considered as a prerequisite for translation extraction from parallel corpora .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We expect the disambiguation to have a beneficial impact on the results given that polysemy is a frequent phenomenon in a general , mixed-domain corpus .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	However , words in a general language corpus like Wikipedia can be polysemous and it is important to identify translations corresponding to their different senses .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We expect that a method capable of identifying the correct sense of the features and translating them accordingly could contribute to producing cleaner vectors and to extracting higher quality lexicons.In this paper , we show how source vectors can be translated into the target language by a cross-lingual Word Sense Disambiguation ( WSD ) method which exploits the output of data-driven Word Sense Induction ( WSI Apidianaki , 2009 and demonstrate how feature disambiguation enhances the quality of the translations extracted from the comparable corpus .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Our experiments are carried out on the English-Slovene language pair but as the methods are totally data-driven , the approach can be easily applied to other languages.The paper is organized as follows : In the next section , we present some related work on bilingual lexicon extraction from comparable corpora .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Moreover , it is clear that disambiguating the vectors improves the quality of the extracted lexicons and manages to beat the simpler , but yet powerful , most frequent translation heuristic .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	The beauty of the bLSA framework is that the model searches for a common latent topic space in an unsupervised fashion , rather than to require manual interaction .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	This paper validated that considering temporality selectively is helpful for improving the translation quality .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Empirical evidence suggests that such algorithms can perform resonably well .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	All these numbers suggest that approximative algorithms are a feasible choice for practical applications .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	However , the quadratic component has such a small coefficient that it does not have any noticable effect on the translation speed for all reasonable inputs .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We assume here that the MT system is capable of providing word alignment ( or equivalent ) information during decoding , which is generally true for current statistical MT systems .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	In such cases partial SRSs must be recorded in such a way that they can be combined later with other partial SRSs .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Considering our semantic features are the most basic ones , using more sophisticated features ( e.g the head words and their translations of the sourceside semantic roles ) provides a possible direction for further experimentation
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	However , our analysis has shown that for Arabic , these genres typically contain more Latin script and transliterated words , and thus there is less morphology to score .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	However , LM statistics are sparse , and they are made sparser by morphological variation .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Qc 2012 Association for Computational LinguisticsIt has also been suggested that this setting requires morphological generation because the bitext may not Pron + Fem + SgVerb + Masc +3 + PlPrtConj contain all inflected variants ( Minkov et al 2007 ; Toutanova et al 2008 ; Fraser et al 2012 However , using lexical coverage experiments , we show thatit there is ample room for translation quality improvements through better selection of forms that already exist in the translation model.they writewilland .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	English is a weakly inflected language : it has a narrow verbal paradigm , restricted nominal inflection ( plurals and only the vestiges of a case system .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	One problem with the dynamic cache is that those initial sentences in a test document may not benefit from the dynamic cache .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Another problem is that the dynamic cache may be prone to noise and cause error propagation .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	At least , the topic of a document can help choose specific translation candidates , since when taken out of the context from their document , some words , phrases and even sentences may be rather ambiguous and thus difficult to understand .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Our motivation to employ similar bilingual document pairs in the training parallel corpus is simple : a human translator often collects similar bilingual document pairs to help translation .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	During last decade , tremendous work has been done to improve the quality of statistical machineCorresponding author .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	However , there have not been until very recently that the application of mixture modelling in SMT has received increasing attention .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Among them , encyclopedias are especially important in that they contain a lot of terms that a morphological dictionary fails to cover .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Most improvements come from correction of over-segmentation because the initial segmentation by the analyzer shows a tendency of oversegmentation .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Historically , researchers have devoted extensive human resources to build and maintain high coverage dictionaries ( Yokoi , 1995 Since the orthography of Japanese does not specify a standard for segmentation , researchers define their own criteria before constructing lexical resources .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We propose an approach that biases machine translation systems toward relevant translations based on topic-specific contexts , where topics are induced in an unsupervised way using topic models ; this can be thought of as inducing subcorpora for adaptation without any human annotation .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Even without recognition errors , speech translation has to cope with a lack of conventional syntactic structures because the structures of spontaneous speech differ from that of written language .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
					</div>
						<button type="button" id="subsubcollapsible" class="collapsible">Sentences in cluster n1</button>
						<div class="content">
							<p> 	We show that it is possible to significantly decrease training and test corpus perplexity of the translation models .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Out-of-vocabulary recognition may have two-sided effects on SMT performance .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	There is also significant disagreement on the specifications , although much of their contents is the same .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We also show that the proposed method effectively addresses the well-known rare word problem in EM-estimated models ; and at the same time induces a much smaller dictionary of bilingual word-pairs .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We also believe that our results may help in the design of effective heuristicsfor some of these tasks .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	In future works , other parameters which influence the performance will be studied , among which the use of a terminological extractor to treat complex terms ( Daille and Morin , 2005 more contextual window configurations , and the use of syntactic information in combination with lexical information ( Yu and Tsujii , 2009 It would also be interesting to compare the projection-based approaches to ( Haghighi et al 2008 ) s generative model for bilingual lexicon acquisition from monolingual corpora .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Context-based projection methods for identifying the translation of terms in comparable corpora has attracted a lot of attention in the community , e.g Fung ,1998 ; Rapp , 1999 Surprisingly , none of those works have systematically investigated the impact of the many parameters controlling their approach .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We show that the algorithmic handles provided by our framework can be employed to develop a very fast decoding algorithm which finds good quality translations .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We show that both of these problems are easy to solve and provide efficient solutions for them .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We have also shown that alternating maximization can be employed tocome up with O ( m2 ) decoding algorithm .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	An additional advantage is that the sense clusters often contain more than one translation and , therefore , provide supplementary material for the comparison of the vectors in the target language .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	An avenue that we intend to explore in future work is to extract translations corresponding to different senses of the headwords .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	The evaluation has demonstrated that our system is both effective and useful in a real-world environment
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	In such case , as Hillary Clinton is a famous female leader , she may be associated with other Chinese female leaders in Chinese corpus , while such association is rarely observed in English corpus , which causes asymmetry .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	That is , Hillary Clinton is atemporal , as Figure 1 shows , such that using such dissimilarity against deciding this pair as a correct translation would be harmful .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	This paper studies named entity translation and proposes selective temporality as a new feature , as using temporal features may be harmful for translating atemporal entities .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	The subject should agree with the verb in both gender and number , but the verb has masculine inflection .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Finally , we conclude this paper in Section 6 We have shown that our cache-based approach significantly improves the performance with the help of various caches , such as the dynamic , static and topic caches , although the cache-based approach may introduce some negative impact onBLEU scores for certain documents.In the future , we will further explore how to reflect document divergence during training and dynamically adjust cache weights according to different documents.There are many useful components in trainingdocuments , such as named entity , event and coreference .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Tiedemann showed that the repetition and consistency are very important when modeling natural language and translation .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Thirdly , reference translations of a test document written by human translators tend to have flexible expressions in order to avoid producing monotonous texts .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	As the translation process continues , the dynamic cache grows and contributes more and more to the translation of subsequent sentences .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Mixture modelling is a standard technique for density estimation , but its use in statistical machine translation ( SMT ) has just started to be explored .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Although supervised segmentation is very competitive , we showed that it can be supplemented + very important to identify hiragana words correctly .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	As hiragana is mainly used to write function words and other basic words , segmentation errors concerning hiragana often bring disastrous effects on applications of morphological analysis .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Word segmentation is the first step of natural language processing for Japanese , Chinese and Thai because they do not delimit words by white-space .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We assume that the meaning of constituents in a noun phrase rarely depends on outer context .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Although external lexical resources for human readers are potentially good knowledge sources , they have not been utilized due to differences in segmentation criteria .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Experiments show that the proposed method efficiently corrects the initial segmentation given by a morphological analyzer .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We can now segment them into words in a more sophisticated way .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We show that incorporating lexical weighting features conditioned on soft domain membership directly into our model is an effective strategy for dynamically biasing SMT towards relevant translations , as evidenced by significant performance gains .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Comparative evaluations with other translation approaches of the Verbmobil prototype system show that the statistical translation is superior , especially in the presence of speech input and ungrammatical input
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 							</p>
							<p>  							</p>
					</div>
</div>
          </div>
        </div>
        <button type="button" id="subcollapsible" class="collapsible">Cluster of Claims (Trigrams)</button>
        <div class="content">
          <div class="row">
            <div class="column">
                <img src="./claims_trigrams.png" alt="plot" width="1000" height="1000">
            </div>
            <div class="column" name="trigram_claims">
							<p> 
							</p>
							<p>  							</p>
						<button type="button" id="subsubcollapsible" class="collapsible">Sentences in cluster n0</button>
						<div class="content">
							<p> 	We show that it is possible to significantly decrease training and test corpus perplexity of the translation models .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	There is also significant disagreement on the specifications , although much of their contents is the same .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We prove that while IBM Models 1-2 are conceptually and computationally simple , computations involving the higher ( and more useful ) models are hard.Since it is unlikely that there exists a poly-language 1 ( Tillman , 2001 Wang , 1997 Germann et al 2003 Udupa et al 2004 The models are independent of the language pair and therefore , can be used to build a translation system for any language pair as long as a parallel corpus of texts is available for training .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	In future works , other parameters which influence the performance will be studied , among which the use of a terminological extractor to treat complex terms ( Daille and Morin , 2005 more contextual window configurations , and the use of syntactic information in combination with lexical information ( Yu and Tsujii , 2009 It would also be interesting to compare the projection-based approaches to ( Haghighi et al 2008 ) s generative model for bilingual lexicon acquisition from monolingual corpora .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	One interesting outcome of this study is that significant gains can be obtained by using an association measure that is rarely used in practice .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We plan to check its adequacy for other domains and verify that LO remains a better association measure for different corpora and domains
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Context-based projection methods for identifying the translation of terms in comparable corpora has attracted a lot of attention in the community , e.g Fung ,1998 ; Rapp , 1999 Surprisingly , none of those works have systematically investigated the impact of the many parameters controlling their approach .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We believe that decoding algorithms derived from our framework can be of practical significance .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We show that both of these problems are easy to solve and provide efficient solutions for them .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We expect that a method capable of identifying the correct sense of the features and translating them accordingly could contribute to producing cleaner vectors and to extracting higher quality lexicons.In this paper , we show how source vectors can be translated into the target language by a cross-lingual Word Sense Disambiguation ( WSD ) method which exploits the output of data-driven Word Sense Induction ( WSI Apidianaki , 2009 and demonstrate how feature disambiguation enhances the quality of the translations extracted from the comparable corpus .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
					</div>
						<button type="button" id="subsubcollapsible" class="collapsible">Sentences in cluster n1</button>
						<div class="content">
							<p> 	We believe that by performing a rescoring on translation word graphs we will obtain a more significant improvement in translation quality .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Out-of-vocabulary recognition may have two-sided effects on SMT performance .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We also show that the proposed method effectively addresses the well-known rare word problem in EM-estimated models ; and at the same time induces a much smaller dictionary of bilingual word-pairs .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We also believe that our results may help in the design of effective heuristicsfor some of these tasks .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	One latent outcome of this work is that Wikipedia is surprisingly suitable for mining medical terms .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	A closer look at the translation candidates obtained when using LL , the most popular association measure in projection-based approaches , shows that they are often collocates of the reference translation .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Still , it is already striking that a direct comparison of them is difficult , if not impossible .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Further , our results offer suggestive evidence that bilingual word embeddings act as high-quality semantic features and embody bilingual translation equivalence across languages .6 We report case-insensitive BLEU7 With 4-gram BLEU metric from .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Nevertheless , they found that human mind is very well capable of deriving dependencies such as morphology , cognates , proper names , spelling variations etc and that this capability was finally at the basis of the better results produced by humans compared to corpus based machine translation .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	As there is a large overlap between the modeled events in the combined probabilistic models , we assume that log-linear combination would result in more improvement of the translation quality than the combination by linear interpolation does .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We show that the algorithmic handles provided by our framework can be employed to develop a very fast decoding algorithm which finds good quality translations .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We have also shown that alternating maximization can be employed tocome up with O ( m2 ) decoding algorithm .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	The results show that data-driven semantic analysis can help to circumvent the need for an external seed dictionary , traditionally considered as a prerequisite for translation extraction from parallel corpora .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We expect the disambiguation to have a beneficial impact on the results given that polysemy is a frequent phenomenon in a general , mixed-domain corpus .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	However , words in a general language corpus like Wikipedia can be polysemous and it is important to identify translations corresponding to their different senses .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	An additional advantage is that the sense clusters often contain more than one translation and , therefore , provide supplementary material for the comparison of the vectors in the target language .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	An avenue that we intend to explore in future work is to extract translations corresponding to different senses of the headwords .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 							</p>
							<p>  							</p>
					</div>
</div>
          </div>
        </div>
      </div>


      <button type="button" class="collapsible">Evidences</button>
      <div class="content">
        <button type="button" id="subcollapsible" class="collapsible">Cluster of Evidences (Bigrams)</button>
        <div class="content">
          <div class="row">
            <div class="column">
                <img src="./evidences_bigrams.png" alt="plot" width="1000" height="1000">
            </div>
            <div class="column" name="bigram_evidences">
							<p> 
							</p>
							<p>  							</p>
						<button type="button" id="subsubcollapsible" class="collapsible">Sentences in cluster n0</button>
						<div class="content">
							<p> 	In our case , by building a topic distribution for the source side of the training data , we abstract the notion of domain to include automatically derived subcorpora with probabilistic membership .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Qc 2012 Association for Computational Linguisticsdata come from ; and even if we do , subcorpus may not be the most useful notion of domain for better translations .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We show that incorporating lexical weighting features conditioned on soft domain membership directly into our model is an effective strategy for dynamically biasing SMT towards relevant translations , as evidenced by significant performance gains .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Conditioning lexical probabilities on the topic biases translations toward topicrelevant output , resulting in significant improvements of up to 1 BLEU and 3 TER on Chinese to English translation over a strong baseline .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	To obtain the lexical probability conditioned on topic distribution , we first compute the expected count ezn ( e , f of a word pair under topic zn : features in the translation model , and interpolating them log-linearly with our other features , thus allowezn ( e , f =p ( zn | di ) cj ( e , f 1 ) ing us to discriminatively optimize their weights on di T xj di an arbitrary objective function .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Depending on the model used to select subcorpora , we can bias our translation toward any arbitrary distinction .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We can construct a topic model once on the training data , and use it infer topics on any test set to adapt the translation model .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	In this work , we consider the underlying latent topics of the documents ( Blei et al 2003 Topic modeling has received some use in SMT , for instance Bilingual LSA adaptation ( Tam et al 2007 and the BiTAM model ( Zhao and Xing , 2006 which uses a bilingual topic model for learning alignment .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We induce unsupervised domains from large corpora , and we incorporate soft , probabilistic domain membership into a translation model .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We show that it is possible to significantly decrease training and test corpus perplexity of the translation models .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	In addition , we perform a rescoring of-Best lists using our maximum entropy model and thereby yield an improvement in translation quality .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We believe that by performing a rescoring on translation word graphs we will obtain a more significant improvement in translation quality .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	This additional information could be : Simple context information : information of the words surrounding the word pair ; Syntactic information : part-of-speech information , syntactic constituent , sentence Semantic information : disambiguation information ( e.g.from WordNet currentspeech or dialog act .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Other authors have applied this approach to language modeling ( Rosenfeld , 1996 ; Martin et al 1999 ; Peters and Klakow , 1999 A short review of the maximum entropy approach is outlined in Section 3 .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Finally , we conclude this paper in Section 6 We have shown that our cache-based approach significantly improves the performance with the help of various caches , such as the dynamic , static and topic caches , although the cache-based approach may introduce some negative impact onBLEU scores for certain documents.In the future , we will further explore how to reflect document divergence during training and dynamically adjust cache weights according to different documents.There are many useful components in trainingdocuments , such as named entity , event and coreference .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Tiedemann showed that the repetition and consistency are very important when modeling natural language and translation .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Statistical machine translation systems are usually trained on a large amount of bilingual sentence pairs and translate one sentence at a time , ignoring document-level information .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	First of all , most of parallel corpora lack the annotation of document boundaries ( Tam , 2007 Secondly , although it is easy to incorporate a new feature into the classical log-linear model ( Och , 2003 it is difficult to capture document-level information and model it via some simple features .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	In order to resolve this problem , this paper employs a topic model to weaken those noisybilingual phrase pairs by recommending the decoder to choose most likely phrase pairs according to the topic words extracted from the target-side text of similar bilingual document pairs .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	In particular , three new features are designed to explore various kinds of document-level information in above three kinds of caches .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Evaluation shows the effectiveness of our cache-based approach to document-level translation with the performance improvement of 0.81 in BLUE score over Moses .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	In ( Civera and Juan , 2006 a mixture extension of IBM model 2 along with a specific dynamicprogramming decoding algorithm were proposed .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	3 Mixture of HMM alignment models Let us suppose that p ( x has been generated using a T-component mixture of HMM alignment models : T p ( x p ( t p ( x y t = 1 T p ( t p ( x , a y , t ) .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	To highlight the advantage of our proposed approach , we compare our results with commercial machine translators Engkoo3 developed in Microsoft Research Asia and Google Translator4 .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	To achieve this goal , we developed a graph alignment algorithm that iteratively reinforces the matching similarity exploiting relational similarity and then extracts correct matches .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	1com430 Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing , pages 430439 , MIT , Massachusetts , USA , 9-11 October 2010 .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Such engine This work was done when the first two authors visited Microsoft Research Asia .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Section 3 then develops our framework .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	To illustrate , Figure 1 demonstrates the query result for Bill Gates , retrieving and visualizing the entity-relationship graph of related people names that frequently co-occur with Bill in English corpus .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	While high quality entity translation is essential in cross-lingual information access and trans lation , it is non-trivial to achieve , due to the challenge that entity translation , though typically bearing pronunciation similarity , can also be arbitrary , e.g Jackie Chan and fiX : it ( pronounced Cheng Long Existing efforts to address these challenges can be categorized into transliterationand corpusbased approaches .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	To illustrate this , an English news article mentioning Bill Gates and Melinda Gates evidences a relationship between the two entities , which can be quantified from their co-occurrences in the entire English Web corpus .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	To summarize , we believe that this paper has the following contributions : We abstract entity translation problem as a graph mapping between entity-relationship graphs in two languages.We develop an effective matching algorithm leveraging both pronunciation and cooccurrence similarity .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We evaluated the adapted LM on SMT and found that the evaluation metrics are crucial to reflect the actual improvement in performance .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	In Section 3 , we present the effect of LM adaptation on word perplexity , followed by SMT experiments reported in BLEU on both speech and text input in Section 3.3 .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We organize the paper as follows : In Section 2 , we introduce the bLSA framework including Latent Dirichlet-Tree Allocation ( LDTA Tam and Schultz , 2007 ) as a correlated LSA model , bLSA training and crosslingual LM adaptation .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	On Chinese to English speech and text translation the proposed bLSA framework successfully reduced word perplexity of the English LM by over 27percent for a unigram LM and up to 13.6 percent for a 4-gram LM .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We interpolated multiple translation models generated by the CWS schemes and found our approaches were very effective in improving the translations .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We also found the correlation between the CWS F-score and SMT BLEU score was very weak .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We have published a much more detailed paper ( Zhang et al 2008 ) to describe the relations between CWS and SMT
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Secondly , we investigated the advantages and disadvantages of various CWS approaches , both dictionary-based and CRF-based , and built CWSs using these approaches to examine their effect on translations .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We proposed a new approach to linear interpolation of translation features .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We investigated the effect of CWS on SMT from two points of view .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Which approach pro 1 A CWS competition organized by the ACL special interest group on Chinese .216 Proceedings of the Third Workshop on Statistical Machine Translation , pages 216223 , Columbus , Ohio , USA , June 2008 .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	In this work , we also propose approaches to make use of all the Sighan training data regardless of the specifications .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We grouped all of the CWS methods into two classes : the class without out-of-vocabulary ( OOV ) recognition and the class with OOV recognition , represented by the dictionary-based CWS and the CRF-based CWS , respectively .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	On the other hand , the dictionarybased approach that does not support OOV recognition produced a lower F-score , but with a relatively weak data spareness problem .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We furthermore suggest the use of hierarchical lexicon models .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Nevertheless , they found that human mind is very well capable of deriving dependencies such as morphology , cognates , proper names , spelling variations etc and that this capability was finally at the basis of the better results produced by humans compared to corpus based machine translation .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We will investigate this in the future .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	It has been successfully applied to realistic tasks in various national and international research programs .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We evaluated our approach on CRL NE data and obtained a higher F-measure than existing approaches that do not use structural information .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We also conducted experiments on IREX NE data and an NE-annotated web corpus and conrmed that structural information improves the performance of NER .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	As a consequence , the performance of NER was improved by using structural information and our approach achieved a higher F-measure than existing approaches
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Qc 2013 Association for Computational Linguistics names in parallel corpora , updating word segmentation , word alignment and grammar extraction ( Section 3.1 We developed a name-aware MT framework which tightly integrates name tagging and name translation into training and decoding of MT. Experiments on Chinese-English translation demonstrated the effectiveness of our approach over a high-quality MT baseline in both overall translation and name translation , especially for formal genres .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Compared to previous methods , the novel contributions of our approach are : 1 .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	This need can be addressed in part by cross-lingual information access tasks such as entity linking ( McNamee et al 2011 ; Cassidy et al 2012 event extraction ( Hakkani-Tur et al 2007 slot filling ( Snover et al 2011 ) and question answering ( Parton et al 2009 ; Parton and McKeown , 2010 A key bottleneck of highquality cross-lingual information access lies in the performance of Machine Translation ( MT Traditional MT approaches focus on the fluency and accuracy of the overall translation but fall short in their ability to translate certain content words including critical information , especially names .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	The feasibility of speech-to-speech translation was the focus of research at the beginning because each component was difficult to build and their integration seemed more difficult .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	The evaluation has demonstrated that our system is both effective and useful in a real-world environment
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We achieved best results when the model training data , MT tuning set , and MT evaluation set conThe bottom category includes all lexical items that the decoder could produce in a translation of the source .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Qc 2012 Association for Computational LinguisticsIt has also been suggested that this setting requires morphological generation because the bitext may not Pron + Fem + SgVerb + Masc +3 + PlPrtConj contain all inflected variants ( Minkov et al 2007 ; Toutanova et al 2008 ; Fraser et al 2012 However , using lexical coverage experiments , we show thatit there is ample room for translation quality improvements through better selection of forms that already exist in the translation model.they writewilland .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	For English-to-Arabic translation , we achieve a +1.04 BLEU average improvement by tiling our model on top of a large LM .146 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics , pages 146155 , Jeju , Republic of Korea , 8-14 July 2012 .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Consider the output of Google Translate for the simple English sentence in Fig. 1 .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Agreement relations that cross statistical phrase boundaries are not explicitly modeled in most phrasebased MT systems ( Avramidis and Koehn , 2008 We address this shortcoming with an agreement model that scores sequences of fine-grained morphosyntactic classes .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	The experience obtained in the Verbmobil project , in particular a large-scale end-to-end evaluation , showed that the statistical approach resulted in significantly lower error rates than three competing translation approaches : the sentence error rate was 29percent in comparison with 52percent to 62percent for the other translation approaches .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	In comparison with written language , speech and especially spontaneous speech poses additional difficulties for the task of automatic translation .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We describe the components of the system and report results on the Verbmobil task .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	In this paper , we have analyzed the complexity of the greedy decoding algorithm originally presented in Germann et al 2001 ) and presented improvements that drastically reduce the decoders complexity and speed to practically linear time.Experimental data suggests a good correlation betweenG1 decoding anddecoding ( with 10 translations per input word considered , a list of 498 candidates for INSERT , a maximum swap distance of 2 and a maximum swap segment size of 5 The profiles shown are cumulative , so that the top curve reflects the total decoding time .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Brute force translation of the 100 short news articles in Chinese from the TIDES MT evaluation in June 2002 ( 878 segments ; ca. 25k tokens ) requires , without any of the improvements described in this paper , over 440 CPU hours , using the simpler , faster algorithm ( de scribed below We will show that this time can be reduced to ca. 40 minutes without sacrificing translation quality .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Using the same evaluation metric ( but different evaluation data Wang and Waibel report search error rates of 7.9 percent and 9.3 respectively , for their decoders .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	IBM Model 4 scores and the BLEU metric .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	The times shown are averages of 100 sentences each for length10 , 20 80 .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Operations not included in the figures consume so little time that their plots can not be discerned in the graphs .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	The speed improvements discussed in this paper make multiple randomized searches per sentence feasible , leading to a faster and better decoder for machine translation with IBM Model 4.6 .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We achieve this by integrating hypothesis evaluation into hypothesis creation , tiling improvements over the translation hypothesis at the end of each search iteration , and by imposing restrictions on the amount of word reordering during decoding .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Och et al. report word error rates of 68.68 percent for optimal search ( based on a variant of the A algorithm and 69.65 percent for the most restricted version of a decoder that combines dynamic programming with a beam search ( Tillmann and Ney , 2000 Germann et al 2001 ) compare translations obtained by a multi-stack decoder and a greedy hill-climbing algorithm against those produced by an optimal integer programming decoder that treats decoding as a variant of the traveling-salesman problem ( cf. Knight , 1999 Their overall performance metric is the sentence error rate ( SER For decoding with IBM Model 3 , they report SERs of about 57 6-word sentences ) and 76 8-word sentences ) for optimal decoding , 58percent and 75percent for stack decoding , and 60percent and 75percent for greedy decoding , which is the focus of this paper .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We validate this selective use of temporal features boosts the accuracy by 6.1 percent .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We developed a classifier to distinguish temporalentities and our proposed method outperforms the state-of-the-art approach by 6.1
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	In contrast , Figure 1 illustrates asymmetry , by showing the frequencies of Usain Bolt , a Jamaican sprinter , and Hillary Clinton , an American politician , in comparable news articles during the year 2008 .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	To overcome such problems , we propose a new notion of selective temporality ( called this fea 2.3 Step 3 : Reinforcement We reinforce R0 by leveraging R and obtain a converged matrix R using the following model : ture ST to distinguish from T ) to automatically distinguish temporal and atemporal entities .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Early efforts of named entity translation have focused on using phonetic feature ( called PH ) to estimate a phonetic similarity between two names ( Knight and Graehl , 1998 ; Li et al 2004 ; Virga and Khudanpur , 2003 In contrast , some approaches have focused on using context feature ( called CX ) which compares surrounding words of entities ( Fung and Yee , 1998 ; Diab and Finch , 2000 ; Laroche and Langlais , 2010 Recently , holistic approaches combining such similarities have been studied ( Shao and Ng , 2004 ; You et al 2010 ; Kim et al 2011 Shao and Ng , 2004 ) rank translation candidates using PH and CX independently and return results with the highest average rank You et al 2010 ) compute initial translation scores using PH and iteratively update the scores using relationship feature ( called R Kim et al 2011 ) boost Yous approach by additionally leveraging CX .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	This paper studies named entity translation and proposes selective temporality as a new feature , as using temporal features may be harmful for translating atemporal entities .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	That is , Hillary Clinton is atemporal , as Figure 1 shows , such that using such dissimilarity against deciding this pair as a correct translation would be harmful .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We expect the disambiguation to have a beneficial impact on the results given that polysemy is a frequent phenomenon in a general , mixed-domain corpus .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We have shown how cross-lingual WSD can be applied to bilingual lexicon extraction from comparable corpora .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Section 3 presents the data used in our experiments and Section 4 provides details on the approach and the experimental setup .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We expect that a method capable of identifying the correct sense of the features and translating them accordingly could contribute to producing cleaner vectors and to extracting higher quality lexicons.In this paper , we show how source vectors can be translated into the target language by a cross-lingual Word Sense Disambiguation ( WSD ) method which exploits the output of data-driven Word Sense Induction ( WSI Apidianaki , 2009 and demonstrate how feature disambiguation enhances the quality of the translations extracted from the comparable corpus .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	To segment each noun phrase , we use nonparametric Bayesian language models ( Goldwater et al 2009 ; Mochihashi et al 2009 Our approach605 Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing , pages 605615 , Edinburgh , Scotland , UK , July 2731 , 2011 .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We apply non-parametric Bayesian language models to segment each noun phrase in these resources according to the statistical behavior of its supposed constituents in text .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	The presence of clarinet , alto and contrabass and others in the main text allowed the model to identext to segment noun phrases in it .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	In this paper , we proposed a new task of Japanese noun phrase segmentation .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	From the experimental results for combining our OOV term translation model with English-Chinese CrossLanguage Information Retrieval ( CLIR ) on the data sets of Text Retrieval Evaluation Conference ( TREC it can be found that the obvious performance improvement for both query translation and retrieval can also be obtained .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Further , our results offer suggestive evidence that bilingual word embeddings act as high-quality semantic features and embody bilingual translation equivalence across languages .6 We report case-insensitive BLEU7 With 4-gram BLEU metric from .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We show good performance on Chinese semantic similarity with bilingual trained embeddings .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We introduce bilingual word embeddings : semantic embeddings associated across two languages in the context of neural language models .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	In their seminal paper on SMT , Brown and his colleagues highlighted the problems we face as we go from IBM Models 1-2 to 3-5 ( Brown et al 1993 ) 3 : As we progress from Model 1 to Model 5 , evaluating the expectations that gives us counts becomes increasingly difficult .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	In ( Knight , 1999 ) it was proved that the Exact Decoding prob Given the model parameters and a sentence f determine the most probable translation of f lem is NP-Hard when the language model is a bigram model .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We believe that our results on the computational complexity of the tasks in SMT will result in a better understanding of these tasks from a theoretical perspective .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	In practice , we are never sure that we have found the Viterbi alignment .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Our results showthat there can not exist a closed form expression ( whose representation is polynomial in the size of the input ) for P ( f | e ) and the counts in the EMiterations for Models 3-5 unless P NP
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	around the Viterbi alignment , i.e. in determining j = 1 tfj | eajdj : aj I = 0 d ( j | i , m the goodness of the Viterbi alignment in compar ison to the rest of the alignments.Decoding is an integral component of all SMT systems ( Wang , Table 1 : IBM Model 3 Here , n ( | e ) is the fertility model , t ( f | e ) is the lexicon model and d ( j | i , m is the distortion model .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	enomial time solution for any of these hardeproblems ( unless P NP and P #P P our results highlight and justify the need for developing polynomial time approximations for these computations .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	The experimental pro tocol we followed is described in Section 3 and we analyze our results in Section 4 .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	In future works , other parameters which influence the performance will be studied , among which the use of a terminological extractor to treat complex terms ( Daille and Morin , 2005 more contextual window configurations , and the use of syntactic information in combination with lexical information ( Yu and Tsujii , 2009 It would also be interesting to compare the projection-based approaches to ( Haghighi et al 2008 ) s generative model for bilingual lexicon acquisition from monolingual corpora .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	A closer look at the translation candidates obtained when using LL , the most popular association measure in projection-based approaches , shows that they are often collocates of the reference translation .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Therefore , LL may fare better in an indirect approach , like the one in ( Daille and Morin , 2005 Moreover , we have seen that the cosine similarity measure and sentence contexts give moreLO is used .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Among the latter , many are translating single-word terms ( Chiao and Zweigenbaum , 2002 ; Dejean et al 2005 ; Prochasson et 1 A stoplist is typically used in order to prevent function words from populating the context vectors .617 Proceedings of the 23rd International Conference on Computational Linguistics ( Coling 2010 pages 617625 , Beijing , August 2010 al 2009 while others are tackling the translation of multi-word terms ( Daille and Morin , 2005 The type of discourse might as well be of concern in some of the studies dedicated to bilingual terminology mining .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Our results show that using the log-odds ratio as the association measure allows for significantly better translation spotting than the log-likelihood .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	While the present work does not investigate all the parameters that could potentially impact results , we believe it constitutes the most complete and systematic comparison made so far with variants of the context-based projection approach .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Naturally , studies differ in the way each cooccurrence ( either window or syntax-based ) is weighted , and a plethora of association scores have been investigated and compared , the likelihood score ( Dunning , 1993 ) being among the most popular .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
					</div>
						<button type="button" id="subsubcollapsible" class="collapsible">Sentences in cluster n1</button>
						<div class="content">
							<p> 	They then learn a mapping from these features to sentence weights , use the sentence weights to bias the model probability estimates and subsequently learn the model weights .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We have been able to obtain a significant better test corpus perplexity and also a slight improvement in translation quality .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	He proposed to employ cache-based language and translation models in a phrase-based SMT system for domain909 Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing , pages 909919 , Edinburgh , Scotland , UK , July 2731 , 2011 .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Section 3 presents our cache-based approach to documentlevel SMT .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Specifically , two types of semantic role features are proposed in this paper : a semantic role reordering feature designed to capture the skeletonlevel permutation , and a semantic role deletion fea716 Proceedings of the 23rd International Conference on Computational Linguistics ( Coling 2010 pages 716724 , Beijing , August 2010 ture designed to penalize missing semantic roles in the target sentence .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Qc 2007 Association for Computational Linguistics taking advantage of the localization phenomenon of word alignment in European languages , and the efficient and exact computation of the E-step and Viterbi alignment by using a dynamic-programming approach .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	In ( Zhao and Xing , 2006 three fairly sophisticated bayesian topical translation models , taking IBM Model 1 as a baseline model , were presented under the bilingual topic admixture model formalism .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Section 4 reports experimental results and Section 5 concludes our work.English PeopleEntityCube GeChinese Renlifang GcAbstracting translation as graph mapping Figure 1 : Illustration of entity-relationship graphs .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Similarly , we can mine Chinese news articles to obtain the re lationships between t Jli Vi and 1 ' 1 li \ itJli Vi .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Our evaluation results empirically validated the accuracy of our algorithm over real-life datasets , and showed the effectiveness on our proposed perspective
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	The key property of the bLSA model is that Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics , pages 520527 , Prague , Czech Republic , June 2007 .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Results showed that our approach significantly reduces the word perplexity on the target language in both cases using ASR hypotheses and manual transcripts .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We will investigate the incorporation of monolingual documents for potentially better bilingual LSA modeling
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We found these approaches were very effective in improving quality of translations .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We tested dictionarybased and CRF-based approaches and found there was no significant difference between the two in the qualty of the resulting translations .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	This approach produced a significant improvement in translation andachieved the best BLEU score of all the CWSschemes .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Chinese word segmentation ( CWS ) is a necessary step in Chinese-English statistical machine translation ( SMT ) and its performance has an impact on the results of SMT .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Experimental results on the German-English Verbmobil Source Language Textmorpho-syntactic AnalysisTransformation f J 1 Global Search : maximize Pr ( e I J e I task are reported .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	In our approach we introduce equivalence classes in order to ignore information not relevant to the translation process .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We introduced four types of structural information to an SVM-based NER system : cache features , coreference relations , syntactic features and caseframe features , and conducted NER experiments on three data .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	The Japanese NER system proposed in ( Nakano and Hirai , 2004 which achieved the highest F-measure among conventional systems , introduced the bunsetsu1 feature in order to consider wider context , but considers only adjacent bunsetsus .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Experiments on Chinese-English translation demonstrated the effectiveness of our approach on enhancing the quality of overall translation , name translation and word alignment over a high-quality MT baseline1 .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Tightly integrate joint bilingual name tagging into MT training by coordinating tagged604 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics , pages 604614 , Sofia , Bulgaria , August 4-9 2013 .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We propose a novel Name-aware MT ( NAMT ) approach which can tightly integrate name processing into the training and decoding processes of an end-to-end MT pipeline , and a new name-aware metric to evaluate MT which can assign different weights to different tokens according to their importance values in a document .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Speech recognition , speech synthesis , and machine translation research started about half a century ago .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	After groundbreaking work for two decades , corpus-based speech and language processing technology have recently enabled the achievement of speech-to-speech translation that is usable in the real world .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	fem The car goes quickly Figure 1 : Ungrammatical Arabic output of Google Translate for the English input The car goes quickly .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	( 1 ll .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Even without recognition errors , speech translation has to cope with a lack of conventional syntactic structures because the structures of spontaneous speech differ from that of written language .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Starting with the Bayes decision rule as in speech recognition , we show how the required probability distributions can be structured into three parts : the language model , the alignment model and the lexicon model .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Comparative evaluations with other translation approaches of the Verbmobil prototype system show that the statistical translation is superior , especially in the presence of speech input and ungrammatical input
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We present improvements to a greedy decoding algorithm for statistical machine translation that reduce its time complexity from at least cubic ( when applied navely ) to practically linear time1 without sacrificing translation quality .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	In Section 5 , we report and discuss the obtained results before concluding and presenting some directions for future work .1 Proceedings of the 6th Workshop on Building and Using Comparable Corpora , pages 110 , Sofia , Bulgaria , August 8 , 2013 .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	The results show that data-driven semantic analysis can help to circumvent the need for an external seed dictionary , traditionally considered as a prerequisite for translation extraction from parallel corpora .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Although supervised segmentation is very competitive , we showed that it can be supplemented + very important to identify hiragana words correctly .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Segmentation for Japanese is a successful field of research , achieving the F-score of nearly 99 Kudo et al 2004 This success rests on a high-coverage dictionary .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	All these aspects will be our research focus in the future
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	On NIST08 Chinese-English translation task , we obtain an improvement of 0.48 BLEU from a competitive baseline ( 30.01 BLEU to 30.49 BLEU ) with the Stanford Phrasal MT system .1393 Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing , pages 13931398 , Seattle , Washington , USA , 18-21 October 2013 .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	When used to compute semantic similarity of phrase pairs , bilingual embeddings improve NIST08 end-to-end machine translation results by just below half a BLEU point .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Instead , we investigate the impact of some major factors influencing projection-based approaches on a task of translating 5,000 terms of the medical domain ( the most studied domain making use of French and English Wikipedia pages extracted monolingually thanks to an information retrieval engine .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	The present discussion only focuses on a few number of representative studies .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	The highest Top 1 precision , 55.2 was reached with the following parameters : sentence contexts , LO , cosine and a 9,000-entry mixed lexicon , with the use of a cognate heuristic .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 							</p>
							<p>  							</p>
					</div>
</div>
          </div>
        </div>
        <button type="button" id="subcollapsible" class="collapsible">Cluster of Evidences (Trigrams)</button>
        <div class="content">
          <div class="row">
            <div class="column">
                <img src="./evidences_trigrams.png" alt="plot" width="1000" height="1000">
            </div>
            <div class="column" name="trigram_evidences">
							<p> 
							</p>
							<p>  							</p>
						<button type="button" id="subsubcollapsible" class="collapsible">Sentences in cluster n0</button>
						<div class="content">
							<p> 	To obtain the lexical probability conditioned on topic distribution , we first compute the expected count ezn ( e , f of a word pair under topic zn : features in the translation model , and interpolating them log-linearly with our other features , thus allowezn ( e , f =p ( zn | di ) cj ( e , f 1 ) ing us to discriminatively optimize their weights on di T xj di an arbitrary objective function .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We can construct a topic model once on the training data , and use it infer topics on any test set to adapt the translation model .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Other authors have applied this approach to language modeling ( Rosenfeld , 1996 ; Martin et al 1999 ; Peters and Klakow , 1999 A short review of the maximum entropy approach is outlined in Section 3 .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Statistical machine translation systems are usually trained on a large amount of bilingual sentence pairs and translate one sentence at a time , ignoring document-level information .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	First of all , most of parallel corpora lack the annotation of document boundaries ( Tam , 2007 Secondly , although it is easy to incorporate a new feature into the classical log-linear model ( Och , 2003 it is difficult to capture document-level information and model it via some simple features .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	In order to resolve this problem , this paper employs a topic model to weaken those noisybilingual phrase pairs by recommending the decoder to choose most likely phrase pairs according to the topic words extracted from the target-side text of similar bilingual document pairs .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	In particular , three new features are designed to explore various kinds of document-level information in above three kinds of caches .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Qc 2007 Association for Computational Linguistics taking advantage of the localization phenomenon of word alignment in European languages , and the efficient and exact computation of the E-step and Viterbi alignment by using a dynamic-programming approach .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Section 4 reports experimental results and Section 5 concludes our work.English PeopleEntityCube GeChinese Renlifang GcAbstracting translation as graph mapping Figure 1 : Illustration of entity-relationship graphs .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	1com430 Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing , pages 430439 , MIT , Massachusetts , USA , 9-11 October 2010 .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We also found the correlation between the CWS F-score and SMT BLEU score was very weak .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We found these approaches were very effective in improving quality of translations .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We tested dictionarybased and CRF-based approaches and found there was no significant difference between the two in the qualty of the resulting translations .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We have published a much more detailed paper ( Zhang et al 2008 ) to describe the relations between CWS and SMT
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Chinese word segmentation ( CWS ) is a necessary step in Chinese-English statistical machine translation ( SMT ) and its performance has an impact on the results of SMT .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	In our approach we introduce equivalence classes in order to ignore information not relevant to the translation process .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
					</div>
						<button type="button" id="subsubcollapsible" class="collapsible">Sentences in cluster n1</button>
						<div class="content">
							<p> 	In our case , by building a topic distribution for the source side of the training data , we abstract the notion of domain to include automatically derived subcorpora with probabilistic membership .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Qc 2012 Association for Computational Linguisticsdata come from ; and even if we do , subcorpus may not be the most useful notion of domain for better translations .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We show that incorporating lexical weighting features conditioned on soft domain membership directly into our model is an effective strategy for dynamically biasing SMT towards relevant translations , as evidenced by significant performance gains .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Conditioning lexical probabilities on the topic biases translations toward topicrelevant output , resulting in significant improvements of up to 1 BLEU and 3 TER on Chinese to English translation over a strong baseline .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Depending on the model used to select subcorpora , we can bias our translation toward any arbitrary distinction .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	In this work , we consider the underlying latent topics of the documents ( Blei et al 2003 Topic modeling has received some use in SMT , for instance Bilingual LSA adaptation ( Tam et al 2007 and the BiTAM model ( Zhao and Xing , 2006 which uses a bilingual topic model for learning alignment .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	They then learn a mapping from these features to sentence weights , use the sentence weights to bias the model probability estimates and subsequently learn the model weights .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We induce unsupervised domains from large corpora , and we incorporate soft , probabilistic domain membership into a translation model .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We show that it is possible to significantly decrease training and test corpus perplexity of the translation models .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	In addition , we perform a rescoring of-Best lists using our maximum entropy model and thereby yield an improvement in translation quality .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We believe that by performing a rescoring on translation word graphs we will obtain a more significant improvement in translation quality .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We have been able to obtain a significant better test corpus perplexity and also a slight improvement in translation quality .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	This additional information could be : Simple context information : information of the words surrounding the word pair ; Syntactic information : part-of-speech information , syntactic constituent , sentence Semantic information : disambiguation information ( e.g.from WordNet currentspeech or dialog act .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Finally , we conclude this paper in Section 6 We have shown that our cache-based approach significantly improves the performance with the help of various caches , such as the dynamic , static and topic caches , although the cache-based approach may introduce some negative impact onBLEU scores for certain documents.In the future , we will further explore how to reflect document divergence during training and dynamically adjust cache weights according to different documents.There are many useful components in trainingdocuments , such as named entity , event and coreference .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Tiedemann showed that the repetition and consistency are very important when modeling natural language and translation .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	He proposed to employ cache-based language and translation models in a phrase-based SMT system for domain909 Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing , pages 909919 , Edinburgh , Scotland , UK , July 2731 , 2011 .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Section 3 presents our cache-based approach to documentlevel SMT .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Evaluation shows the effectiveness of our cache-based approach to document-level translation with the performance improvement of 0.81 in BLUE score over Moses .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Specifically , two types of semantic role features are proposed in this paper : a semantic role reordering feature designed to capture the skeletonlevel permutation , and a semantic role deletion fea716 Proceedings of the 23rd International Conference on Computational Linguistics ( Coling 2010 pages 716724 , Beijing , August 2010 ture designed to penalize missing semantic roles in the target sentence .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	In ( Civera and Juan , 2006 a mixture extension of IBM model 2 along with a specific dynamicprogramming decoding algorithm were proposed .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	In ( Zhao and Xing , 2006 three fairly sophisticated bayesian topical translation models , taking IBM Model 1 as a baseline model , were presented under the bilingual topic admixture model formalism .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	3 Mixture of HMM alignment models Let us suppose that p ( x has been generated using a T-component mixture of HMM alignment models : T p ( x p ( t p ( x y t = 1 T p ( t p ( x , a y , t ) .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Similarly , we can mine Chinese news articles to obtain the re lationships between t Jli Vi and 1 ' 1 li \ itJli Vi .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	To highlight the advantage of our proposed approach , we compare our results with commercial machine translators Engkoo3 developed in Microsoft Research Asia and Google Translator4 .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Our evaluation results empirically validated the accuracy of our algorithm over real-life datasets , and showed the effectiveness on our proposed perspective
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	To achieve this goal , we developed a graph alignment algorithm that iteratively reinforces the matching similarity exploiting relational similarity and then extracts correct matches .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Such engine This work was done when the first two authors visited Microsoft Research Asia .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Section 3 then develops our framework .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	To illustrate , Figure 1 demonstrates the query result for Bill Gates , retrieving and visualizing the entity-relationship graph of related people names that frequently co-occur with Bill in English corpus .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	While high quality entity translation is essential in cross-lingual information access and trans lation , it is non-trivial to achieve , due to the challenge that entity translation , though typically bearing pronunciation similarity , can also be arbitrary , e.g Jackie Chan and fiX : it ( pronounced Cheng Long Existing efforts to address these challenges can be categorized into transliterationand corpusbased approaches .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	To illustrate this , an English news article mentioning Bill Gates and Melinda Gates evidences a relationship between the two entities , which can be quantified from their co-occurrences in the entire English Web corpus .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	To summarize , we believe that this paper has the following contributions : We abstract entity translation problem as a graph mapping between entity-relationship graphs in two languages.We develop an effective matching algorithm leveraging both pronunciation and cooccurrence similarity .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We evaluated the adapted LM on SMT and found that the evaluation metrics are crucial to reflect the actual improvement in performance .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	In Section 3 , we present the effect of LM adaptation on word perplexity , followed by SMT experiments reported in BLEU on both speech and text input in Section 3.3 .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We organize the paper as follows : In Section 2 , we introduce the bLSA framework including Latent Dirichlet-Tree Allocation ( LDTA Tam and Schultz , 2007 ) as a correlated LSA model , bLSA training and crosslingual LM adaptation .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	The key property of the bLSA model is that Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics , pages 520527 , Prague , Czech Republic , June 2007 .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Results showed that our approach significantly reduces the word perplexity on the target language in both cases using ASR hypotheses and manual transcripts .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	On Chinese to English speech and text translation the proposed bLSA framework successfully reduced word perplexity of the English LM by over 27percent for a unigram LM and up to 13.6 percent for a 4-gram LM .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We will investigate the incorporation of monolingual documents for potentially better bilingual LSA modeling
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We interpolated multiple translation models generated by the CWS schemes and found our approaches were very effective in improving the translations .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	This approach produced a significant improvement in translation andachieved the best BLEU score of all the CWSschemes .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Secondly , we investigated the advantages and disadvantages of various CWS approaches , both dictionary-based and CRF-based , and built CWSs using these approaches to examine their effect on translations .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We proposed a new approach to linear interpolation of translation features .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We investigated the effect of CWS on SMT from two points of view .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Which approach pro 1 A CWS competition organized by the ACL special interest group on Chinese .216 Proceedings of the Third Workshop on Statistical Machine Translation , pages 216223 , Columbus , Ohio , USA , June 2008 .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	In this work , we also propose approaches to make use of all the Sighan training data regardless of the specifications .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We grouped all of the CWS methods into two classes : the class without out-of-vocabulary ( OOV ) recognition and the class with OOV recognition , represented by the dictionary-based CWS and the CRF-based CWS , respectively .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	On the other hand , the dictionarybased approach that does not support OOV recognition produced a lower F-score , but with a relatively weak data spareness problem .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Experimental results on the German-English Verbmobil Source Language Textmorpho-syntactic AnalysisTransformation f J 1 Global Search : maximize Pr ( e I J e I task are reported .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We furthermore suggest the use of hierarchical lexicon models .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Nevertheless , they found that human mind is very well capable of deriving dependencies such as morphology , cognates , proper names , spelling variations etc and that this capability was finally at the basis of the better results produced by humans compared to corpus based machine translation .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We will investigate this in the future .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	It has been successfully applied to realistic tasks in various national and international research programs .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We evaluated our approach on CRL NE data and obtained a higher F-measure than existing approaches that do not use structural information .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We also conducted experiments on IREX NE data and an NE-annotated web corpus and conrmed that structural information improves the performance of NER .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We introduced four types of structural information to an SVM-based NER system : cache features , coreference relations , syntactic features and caseframe features , and conducted NER experiments on three data .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	As a consequence , the performance of NER was improved by using structural information and our approach achieved a higher F-measure than existing approaches
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	The Japanese NER system proposed in ( Nakano and Hirai , 2004 which achieved the highest F-measure among conventional systems , introduced the bunsetsu1 feature in order to consider wider context , but considers only adjacent bunsetsus .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Qc 2013 Association for Computational Linguistics names in parallel corpora , updating word segmentation , word alignment and grammar extraction ( Section 3.1 We developed a name-aware MT framework which tightly integrates name tagging and name translation into training and decoding of MT. Experiments on Chinese-English translation demonstrated the effectiveness of our approach over a high-quality MT baseline in both overall translation and name translation , especially for formal genres .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Compared to previous methods , the novel contributions of our approach are : 1 .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Experiments on Chinese-English translation demonstrated the effectiveness of our approach on enhancing the quality of overall translation , name translation and word alignment over a high-quality MT baseline1 .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Tightly integrate joint bilingual name tagging into MT training by coordinating tagged604 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics , pages 604614 , Sofia , Bulgaria , August 4-9 2013 .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	This need can be addressed in part by cross-lingual information access tasks such as entity linking ( McNamee et al 2011 ; Cassidy et al 2012 event extraction ( Hakkani-Tur et al 2007 slot filling ( Snover et al 2011 ) and question answering ( Parton et al 2009 ; Parton and McKeown , 2010 A key bottleneck of highquality cross-lingual information access lies in the performance of Machine Translation ( MT Traditional MT approaches focus on the fluency and accuracy of the overall translation but fall short in their ability to translate certain content words including critical information , especially names .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	We propose a novel Name-aware MT ( NAMT ) approach which can tightly integrate name processing into the training and decoding processes of an end-to-end MT pipeline , and a new name-aware metric to evaluate MT which can assign different weights to different tokens according to their importance values in a document .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 	Speech recognition , speech synthesis , and machine translation research started about half a century ago .
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 
							</p>
							<p>  							</p>
							<p> 							</p>
							<p>  							</p>
					</div>
</div>
            </div>
          </div>
        </div>
      </div>


      <script>
        var coll = document.getElementsByClassName("collapsible");
        var i;

        for (i = 0; i < coll.length; i++) {
          coll[i].addEventListener("click", function() {
            this.classList.toggle("active");
            var content = this.nextElementSibling;
            if (content.style.display === "block") {
              content.style.display = "none";
            } else {
              content.style.display = "block";
            }
          });
        }
      </script>

    </body>
</html>
