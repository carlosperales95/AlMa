 In statistical machine translation, cor respondences between the words in the source and the target language are learned from bilingual corpora on the basis of so called alignment models. Existing statistical systems for MT of ten treat different derivatives of the same lemma as if they were indepen dent of each other. In this paper we argue that a better exploitation of the bilingual training data can be achieved by explicitly taking into account the in terdependencies of the different deriva tives. We do this along two direc tions: Usage of hierarchical lexicon models and the introduction of equiv alence classes in order to ignore in formation not relevant for the trans lation task. The improvement of the translation results is demonstrated on a German-English corpus. 

 We have presented methods for a better exploitation of the bilingual training data for statistical machine translation by explicitly taking into account the interdependencies of the different derivatives of the same base form. We suggest the usage of hierarchical models as well as an alternative representation of the data in combination with the identification and omission of information not relevant for the translation task. First experiments prove their general applicability to realistic tasks such as spontaneously spoken dialogs. We expect the described methods to yield more improvement of the translation quality for cases where much smaller amounts of training data are available. As there is a large overlap between the modeled events in the combined probabilistic models, we assume that log-linear combination would result in more improvement of the translation quality than the combination by linear interpolation does. We will investigate this in the future. We also plan to integrate the decision regarding the choice of readings into the search process. full form lexicon.  
