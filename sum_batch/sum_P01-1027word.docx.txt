Typically, the lexicon models used in statistical machine translation systems do not include any kind of linguistic or contextual information, which often leads to problems in performing a correct word sense disambiguation. One way to deal with this problem within the statistical framework is to use maximum entropy methods. In this paper, we present how to use this type of information within a statistical machine translation system. We show that it is possible to significantly decrease training and test corpus perplexity of the translation models. In addition, we perform a rescoring of  -Best lists using our maximum entropy model and thereby yield an improvement in translation quality. Experimental results are presented on the so-called “Verbmobil Task”.

We have developed refined lexicon models for statistical machine translation by using maximum entropy models. We have been able to obtain a significant better test corpus perplexity and also a slight improvement in translation quality. We believe that by performing a rescoring on translation word graphs we will obtain a more significant improvement in translation quality. For the future we plan to investigate more refined feature selection methods in order to make the maximum entropy models smaller and bettergeneralizing. In addition, we want to investigate more syntactic, semantic features and to include features that go beyond sentence boundaries. 
