Typically, the lexicon models used in statistical machine translation systems do not include any kind of linguistic or contextual information, which often leads to problems in performing a correct word sense disambiguation. One way to deal with this problem within the statistical framework is to use maximum entropy methods. In this paper, we present how to use this type of information within a statistical machine translation system. We show that it is possible to significantly decrease training and test corpus perplexity of the translation models. In addition, we perform a rescoring of  -Best lists using our maximum entropy model and thereby yield an improvement in translation quality. Experimental results are presented on the so-called “Verbmobil Task”.

 Typically, the lexicon models used in statistical machine translation systems are only single-word based, that is one word in the source language corresponds to only one word in the target language. Those lexicon models lack from context information that can be extracted from the same parallel corpus. This additional information could be: Simple context information: information of the words surrounding the word pair; Syntactic information:	part-of-speech information, syntactic constituent, sentence Semantic information: disambiguation information (e.g.  from WordNet), current/previous speech or dialog act. To include this additional information within the statistical framework we use the maximum entropy approach. This approach has been applied in natural language processing to a variety of tasks. (Berger et al., 1996) applies this approach to the so-called IBM Candide system to build context dependent models, compute automatic sentence splitting and to improve word reordering in translation. Similar techniques are used in (Papineni et al., 1996; Papineni et al., 1998) for socalled direct translation models instead of those proposed in (Brown et al., 1993). (Foster, 2000) describes two methods for incorporating information about the relative position of bilingual word pairs into a maximum entropy translation model. Other authors have applied this approach to language modeling (Rosenfeld, 1996; Martin et al., 1999; Peters and Klakow, 1999). A short review of the maximum entropy approach is outlined in Section 3. 2 

We have developed refined lexicon models for statistical machine translation by using maximum entropy models. We have been able to obtain a significant better test corpus perplexity and also a slight improvement in translation quality. We believe that by performing a rescoring on translation word graphs we will obtain a more significant improvement in translation quality. For the future we plan to investigate more refined feature selection methods in order to make the maximum entropy models smaller and bettergeneralizing. In addition, we want to investigate more syntactic, semantic features and to include features that go beyond sentence boundaries. 
