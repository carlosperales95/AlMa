We present improvements to a greedy decoding algorithm for statistical machine translation that reduce its time complexity from at least cubic (  when applied na¨ıvely) to practically linear time1 without sacrificing translation quality. We achieve this by integrating hypothesis evaluation into hypothesis creation, tiling improvements over the translation hypothesis at the end of each search iteration, and by imposing restrictions on the amount of word reordering during decoding.

In this paper, we have analyzed the complexity of the greedy decoding algorithm originally presented in Germann et al. (2001) and presented improvements that drastically reduce the decoder’s complexity and speed to practically linear time.Experimental data suggests a good correlation betweenG1 decoding anddecoding (with 10 translations per input word con-sidered, a list of 498 candidates for INSERT, a maximum swap distance of 2 and a maximum swap segment size of 5). The profiles shown are cumulative, so that the top curve reflects the total decoding time. To put the times for decoding in perspective, the dashed line in the lower plot reflects the total decoding time in decoding. Operations not included in the figures consume so little time that their plots cannot be discerned in the graphs. The times shown are averages of 100 sentences each for length10, 20, , 80.IBM Model 4 scores and the BLEU metric. The speed improvements discussed in this paper make multiple randomized searches per sentence feasible, leading to a faster and better decoder for machine translation with IBM Model 4.6 
