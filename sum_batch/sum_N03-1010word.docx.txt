 We present improvements to a greedy decod ing algorithm for statistical machine translation that reduce its time complexity from at least cubic (  when applied na¨ıvely) to prac tically linear time1 without sacrificing trans lation quality. We achieve this by integrat ing hypothesis evaluation into hypothesis cre ation, tiling improvements over the translation hypothesis at the end of each search iteration, and by imposing restrictions on the amount of word reordering during decoding. 

 In this paper, we have analyzed the complexity of the greedy decoding algorithm originally presented in Germann et al. (2001) and presented improvements that drastically reduce the decoder’s complexity and speed to practically linear time. Experimental data suggests a good correlation between G1 decoding  and	decoding (with 10 translations per input word con sidered, a list of 498 candidates for INSERT, a maximum swap distance of 2 and a maximum swap segment size of 5). The profiles shown are cumulative, so that the top curve reflects the total decoding time. To put the times for decoding in perspective, the dashed line in the lower plot reflects the total decoding time in decoding. Operations not included in the figures consume so little time that their plots cannot be discerned in the graphs. The times shown are averages of 100 sentences each for length 10, 20, , 80. IBM Model 4 scores and the BLEU metric. The speed improvements discussed in this paper make multiple randomized searches per sentence feasible, leading to a faster and better decoder for machine translation with IBM Model 4. 
