 (1)	 ._}...-ll  .  When automatically translating from a weakly inflected source language like English to a tar get language with richer grammatical features such as gender and dual number, the output commonly contains morpho-syntactic agree ment errors. To address this issue, we present a target-side, class-based agreement model. Agreement is promoted by scoring a sequence of fine-grained morpho-syntactic classes that are predicted during decoding for each transla tion hypothesis. For English-to-Arabic transla tion, our model yields a +1.04 BLEU average improvement over a state-of-the-art baseline. The model does not require bitext or phrase ta ble annotations and can be easily implemented as a feature in many phrase-based decoders. 

 Our class-based agreement model improves translation quality by promoting local agreement, but with a minimal increase in decoding time and no additional storage requirements for the phrase table. The model can be implemented with a standard CRF package, trained on existing treebanks for many languages, and integrated easily with many MT feature APIs. We achieved best results when the model training data, MT tuning set, and MT evaluation set con    The bottom category includes all lexical items that the decoder could produce in a translation of the source. This large gap between the unigram recall of the actual translation output (top) and the lexical coverage of the phrase-based model (bottom) indicates that translation performance can be improved dramatically by altering the translation model through features such as ours, without expanding the search space of the decoder. mixed genre evaluation sets. In principle, our class-based model should be more robust to unseen word types and other phenomena that make non-newswire genres challenging. However, our analysis has shown that for Arabic, these genres typically contain more Latin script and transliterated words, and thus there is less morphology to score. One potential avenue of future work would be to adapt our component models to new genres by self-training them on the target side of a large bitext. 10 To focus on possibly inflected word forms, we excluded	 	 numbers and punctuation from this analysis. 11 The annotator was the first author. 
