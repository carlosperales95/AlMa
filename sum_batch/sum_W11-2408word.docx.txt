Reasoning about ordinary human situations and activities requires the availability of diverse types of knowledge, including expectations about the probable results of actions and the lexical entailments for many predicates. We describe initial work to acquire such a collection of conditional (ifthen) knowledge by exploiting presuppositional discourse patterns (such as ones involving but, yet, and hoping to) and abstracting the matched material into general rules.

Enabling an inference system to reason about common situations and activities requires more types of general world knowledge and lexical knowledge than are currently available or have been targeted by previous work. Weve suggested an initial approach toacquiring rules describing complex consequences or reasons and subtle relations among adjectival attributes: We find possible rules by looking at interesting discourse patterns and rewriting them as conditional expressions based on semantic patterns. A natural question is why we dont use the machine-learningtechniques that are common in other work on acquiring rules. These techniques are particularly successful whenthey are aimed at finding fixed types of relationships, such as hyponymy, near-synonymy, part-of, or causal relations between pairs of lexical items (often nominals or verbs andthe fixed type of relationship between the lexical items is hinted at sufficiently often either by their co-occurrence in certain local lexicosyntactic patterns, or by their occurrences in similar sentential environments (distributional similarity But in our case,we are looking for a broad range of (more or less strong) consequence relationships, andthe relationships are between entire clauses, not lexical items. We are simply not likely to find multiple occurrences of the same pair of clauses in a variety of syntactic configurations, all indicating a consequence relationyoure unlikely to find multiple redundant patterns relating clauses, as in Went up to the door but didnt knock on it. There is more work to be done to arrive at a reliable, inference-ready knowledge base of such rules. The primary desideratum is to produce a logical representation for the rules such that they can be used in the EPILOG reasoner (Schubert and Hwang, 2000 Computing logical forms (as, e.g in Bos (2008 and then deriving logically formulated rules from these rather than deriving sentential forms directly from text should also allow us to be more precise about dropping modifiers, reshaping into generic present tense from other tenses, and other issues that affect the quality of the statements. We have a preliminary version of a logical form generator that derives LFs from TreeBank parses that can support this direction. Further filtering techniques (based both on the surface form and the logical form) should keep the desired inference rules while improving quality 
