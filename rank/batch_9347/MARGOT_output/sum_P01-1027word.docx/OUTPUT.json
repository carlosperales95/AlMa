{"document":[{"claim_score":-0.17167886,"evidence_score":-0.7182162,"text":"Abstract Typically , the lexicon models used in statistical machine translation systems do not include any kind of linguistic or contextual information , which often leads to problems in performing a cor rect word sense disambiguation ."},{"claim_score":-0.65263553,"evidence_score":-0.69225646,"text":"One way to deal with this problem within the statistical framework is to use max imum entropy methods ."},{"claim_score":-1.8272197,"evidence_score":-0.44898773,"text":"In this paper , we present how to use this type of in formation within a statistical machine translation system ."},{"claim_score":0.28591355,"evidence":"We show that it is possible to significantly decrease train ing and test corpus perplexity of the translation models .","evidence_score":1.0588199,"text":"We show that it is possible to significantly decrease train ing and test corpus perplexity of the translation models .","claim_evidence":"it is possible to significantly decrease train ing and test corpus perplexity of the translation models"},{"claim_score":-0.54314189,"evidence":"In addition , we per form a rescoring of - Best lists us ing our maximum entropy model and thereby yield an improvement in trans lation quality .","evidence_score":0.57033885,"text":"In addition , we per form a rescoring of - Best lists us ing our maximum entropy model and thereby yield an improvement in trans lation quality ."},{"claim_score":-1.2919384,"evidence_score":-0.33343759,"text":"Experimental results are presented on the so-called `` Verbmobil Task '' ."},{"claim_score":-0.86760949,"evidence_score":-0.27139734,"text":"Introduction Introduction Typically , the lexicon models used in statistical machine translation systems are only single-word based , that is one word in the source language corresponds to only one word in the target language ."},{"claim_score":-0.80289224,"evidence_score":-0.2488423,"text":"Those lexicon models lack from context information that can be extracted from the same parallel corpus ."},{"claim_score":-0.34562657,"evidence":"This additional information could be : Simple context information : information of the words surrounding the word pair ; Syntactic information : part-of-speech information , syntactic constituent , sentence Semantic information : disambiguation information ( e.g. from WordNet ) , current/previous speech or dialog act .","evidence_score":0.11861871,"text":"This additional information could be : Simple context information : information of the words surrounding the word pair ; Syntactic information : part-of-speech information , syntactic constituent , sentence Semantic information : disambiguation information ( e.g. from WordNet ) , current/previous speech or dialog act ."},{"claim_score":-1.9014649,"evidence_score":-0.47958984,"text":"To include this additional information within the statistical framework we use the maximum entropy approach ."},{"claim_score":-1.2490349,"evidence_score":-0.97811021,"text":"This approach has been applied in natural language processing to a variety of tasks ."},{"claim_score":-1.8065657,"evidence_score":-0.50873584,"text":"( Berger et al. , 1996 ) applies this approach to the so-called IBM Candide system to build context depende Conclusions"}]}