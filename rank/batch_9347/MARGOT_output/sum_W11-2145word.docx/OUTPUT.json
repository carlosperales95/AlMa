{"document":[{"claim_score":-1.8681916,"evidence_score":-0.51081716,"text":"Abstract This paper describes the phrase-based SMT systems developed for our participation in the WMT11 Shared Translation Task ."},{"claim_score":-1.0727046,"evidence_score":-0.95005309,"text":"Translations for English ↔ German and English ↔ French were generated using a phrase-based translation system which is extended by additional models such as bilingual and fine-grained POS language models , POS-based reordering , lattice phrase extraction and discriminative word alignment ."},{"claim_score":-1.0834739,"evidence_score":-0.10400752,"text":"Furthermore , we present a special filtering method for the English-French Giga corpus and the phrase scoring step in the training is parallelized ."},{"claim_score":-2.5049577,"evidence_score":-0.040874642,"text":"Introduction Introduction In this paper we describe our systems for the EMNLP 2011 Sixth Workshop on Statistical Machine Translation ."},{"claim_score":-2.242408,"evidence":"We participated in the Shared Translation Task and submitted translations for English ↔ German and English ↔ French .","evidence_score":0.22896117,"text":"We participated in the Shared Translation Task and submitted translations for English ↔ German and English ↔ French ."},{"claim_score":-0.86991387,"evidence_score":-0.43097123,"text":"We use a phrase-based decoder that can use lattices as input and developed several models that extend the standard log-linear model combination of phrase-based MT. These include advanced reordering models and corresponding adaptations to the phrase extraction process as well as extension to the translation and language model in form of discriminative word alignment and a bilingual language model to extend source word context ."},{"claim_score":-1.7426214,"evidence_score":-0.64866772,"text":"For English-German , language models based on fine-grained part-of-speech tags were used to address the difficult target language generation due to the rich morphology of German ."},{"claim_score":-1.0369456,"evidence":"We also present a filtering method directly addressing the problems of web-craw Conclusions We have presented the systems for our participation in the WMT 2011 Evaluation for English ↔ German and English ↔ French .","evidence_score":0.14211331,"text":"We also present a filtering method directly addressing the problems of web-craw Conclusions We have presented the systems for our participation in the WMT 2011 Evaluation for English ↔ German and English ↔ French ."},{"claim_score":-1.9983369,"evidence_score":-0.41922719,"text":"For English ↔ French , a spe cial filtering method for web-crawled data was developed ."},{"claim_score":-0.56336684,"evidence":"In addition , a parallel phrase scoring technique was implemented that could speed up the MT training process tremendously .","evidence_score":0.22910382,"text":"In addition , a parallel phrase scoring technique was implemented that could speed up the MT training process tremendously ."},{"claim_score":-2.3097941,"evidence_score":-0.4366673,"text":"Using these two features , we were able to integrate the huge amounts of data available in the Giga corpus into our systems translating between English and French ."},{"claim_score":-1.1422699,"evidence":"We applied POS-based reordering to improve our translations in all directions , using short-range re ordering for English ↔ French and long-range re ordering for English ↔ German .","evidence_score":0.23039153,"text":"We applied POS-based reordering to improve our translations in all directions , using short-range re ordering for English ↔ French and long-range re ordering for English ↔ German ."},{"claim_score":-0.88189058,"evidence_score":-0.23129712,"text":"For German English , reordering also the training corpus lead to further improvements of the translation quality ."},{"claim_score":-1.5143254,"evidence":"A Discriminative Word Alignment Model led to an increase in BLEU for English-German .","evidence_score":0.040337578,"text":"A Discriminative Word Alignment Model led to an increase in BLEU for English-German ."},{"claim_score":-2.2228637,"evidence_score":-0.41971392,"text":"For this direction we also tried fine-grained POS language models of different n-gram lengths ."},{"claim_score":-0.48118623,"evidence_score":-0.81558289,"text":"The best translations could be obtained by using 4-grams ."},{"claim_score":-0.55223161,"evidence_score":-0.31313681,"text":"For nearly all experiments , a bilingual language model was applied that expands the context of source words that can be considered during decoding ."},{"claim_score":-0.75496636,"evidence_score":-0.24012643,"text":"The improvements range from 0.1 to 0.4 in BLEU score ."}]}