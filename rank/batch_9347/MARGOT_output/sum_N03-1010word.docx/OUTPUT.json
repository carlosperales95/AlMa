{"document":[{"claim_score":-1.2664778,"evidence":"Abstract We present improvements to a greedy decod ing algorithm for statistical machine translation that reduce its time complexity from at least cubic ( when applied na ¨ ıvely ) to prac tically linear time1 without sacrificing trans lation quality .","evidence_score":0.50383293,"text":"Abstract We present improvements to a greedy decod ing algorithm for statistical machine translation that reduce its time complexity from at least cubic ( when applied na ¨ ıvely ) to prac tically linear time1 without sacrificing trans lation quality ."},{"claim_score":-0.60887769,"evidence_score":-0.0560025,"text":"We achieve this by integrat ing hypothesis evaluation into hypothesis cre ation , tiling improvements over the translation hypothesis at the end of each search iteration , and by imposing restrictions on the amount of word reordering during decoding ."},{"claim_score":-1.8042121,"evidence_score":-0.434783,"text":"Introduction Introduction Most of the current work in statistical machine translation builds on word replacement models developed at IBM in the early 1990s ( Brown et al. , 1990 , 1993 ; Berger et al. , 1994 , 1996 ) ."},{"claim_score":-2.0799365,"evidence_score":-1.1117309,"text":"Based on the conventions established in Brown et al. ( 1993 ) , these models are commonly referred to as the ( IBM ) Models 1-5 ."},{"claim_score":-1.0369586,"evidence_score":-0.5354165,"text":"One of the big challenges in building actual MT systems within this framework is that of decoding : finding the translation candidate that maximizes the translation probability for the given input ."},{"claim_score":-0.85693753,"evidence_score":-0.47388615,"text":"Knight ( 1999 ) has shown the problem to be NP-complete ."},{"claim_score":-0.93067743,"evidence_score":-0.62513992,"text":"Due to the complexity of the task , practical MT systems usually do not employ optimal decoders ( that is , decoders that are guaranteed to find an optimal solution within the constraints of the framework ) , but rely on approximative algorithms instead ."},{"claim_score":0.81781931,"evidence_score":-0.55596426,"claim":"such algorithms can perform resonably well","text":"Empirical evidence suggests that such algorithms can perform resonably well ."},{"claim_score":-2.0372805,"evidence_score":-0.15246205,"text":"For example , Berger et al. ( 1994 ) , Conclusions In this paper , we have analyzed the complexity of the greedy decoding algorithm originally presented in Germann et al. ( 2001 ) and presented improvements that drastically reduce the decoder 's complexity and speed to practically linear time ."},{"claim_score":0.28694216,"evidence_score":-0.2997077,"claim":"Experimental data suggests a good correlation between G1 decoding","text":"Experimental data suggests a good correlation between G1 decoding"}]}