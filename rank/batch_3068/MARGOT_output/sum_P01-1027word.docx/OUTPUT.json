{"document":[{"claim_score":-0.42964526,"evidence_score":-0.80258257,"text":"Typically , the lexicon models used in statistical machine translation systems do not include any kind of linguistic or contextual information , which often leads to problems in performing a correct word sense disambiguation ."},{"claim_score":-0.64988415,"evidence_score":-0.63363005,"text":"One way to deal with this problem within the statistical framework is to use maximum entropy methods ."},{"claim_score":-1.7279627,"evidence_score":-0.25892927,"text":"In this paper , we present how to use this type of information within a statistical machine translation system ."},{"claim_score":0.22870353,"evidence":"We show that it is possible to significantly decrease training and test corpus perplexity of the translation models .","evidence_score":1.1620379,"text":"We show that it is possible to significantly decrease training and test corpus perplexity of the translation models .","claim_evidence":"it is possible to significantly decrease training and test corpus perplexity of the translation models"},{"claim_score":-0.49666544,"evidence":"In addition , we perform a rescoring of - Best lists using our maximum entropy model and thereby yield an improvement in translation quality .","evidence_score":0.36567866,"text":"In addition , we perform a rescoring of - Best lists using our maximum entropy model and thereby yield an improvement in translation quality ."},{"claim_score":-1.2919384,"evidence_score":-0.33343759,"text":"Experimental results are presented on the so-called `` Verbmobil Task '' ."},{"claim_score":-1.2666691,"evidence_score":-1.0050515,"text":"Typically , the lexicon models used in statistical machine translation systems are only single-word based , that is one word in the source language corresponds to only one word in the target language ."},{"claim_score":-0.80289224,"evidence_score":-0.2488423,"text":"Those lexicon models lack from context information that can be extracted from the same parallel corpus ."},{"claim_score":-0.34562657,"evidence":"This additional information could be : Simple context information : information of the words surrounding the word pair ; Syntactic information : part-of-speech information , syntactic constituent , sentence Semantic information : disambiguation information ( e.g. from WordNet ) , current/previous speech or dialog act .","evidence_score":0.11861871,"text":"This additional information could be : Simple context information : information of the words surrounding the word pair ; Syntactic information : part-of-speech information , syntactic constituent , sentence Semantic information : disambiguation information ( e.g. from WordNet ) , current/previous speech or dialog act ."},{"claim_score":-1.9014649,"evidence_score":-0.47958984,"text":"To include this additional information within the statistical framework we use the maximum entropy approach ."},{"claim_score":-1.2490349,"evidence_score":-0.97811021,"text":"This approach has been applied in natural language processing to a variety of tasks ."},{"claim_score":-1.2964311,"evidence_score":-0.4002422,"text":"( Berger et al. , 1996 ) applies this approach to the so-called IBM Candide system to build context dependent models , compute automatic sentence splitting and to improve word reordering in translation ."},{"claim_score":-2.0864255,"evidence_score":-0.85066301,"text":"Similar techniques are used in ( Papineni et al. , 1996 ; Papineni et al. , 1998 ) for socalled direct translation models instead of those proposed in ( Brown et al. , 1993 ) ."},{"claim_score":-2.1835383,"evidence_score":-0.32925528,"text":"( Foster , 2000 ) describes two methods for incorporating information about the relative position of bilingual word pairs into a maximum entropy translation model ."},{"claim_score":-2.5767654,"evidence_score":-0.18767023,"text":"Other authors have applied this approach to language modeling ( Rosenfeld , 1996 ; Martin et al. , 1999 ; Peters and Klakow , 1999 ) ."},{"claim_score":-1.5672417,"evidence_score":-0.66709458,"text":"A short review of the maximum entropy approach is outlined in Section 3 ."},{"claim_score":-1.3781016,"evidence_score":-0.097648716,"text":"2 We have developed refined lexicon models for statistical machine translation by using maximum entropy models ."},{"claim_score":-0.81306344,"evidence":"We have been able to obtain a significant better test corpus perplexity and also a slight improvement in translation quality .","evidence_score":0.4361579,"text":"We have been able to obtain a significant better test corpus perplexity and also a slight improvement in translation quality ."},{"claim_score":0.16814659,"evidence":"We believe that by performing a rescoring on translation word graphs we will obtain a more significant improvement in translation quality .","evidence_score":0.63124473,"text":"We believe that by performing a rescoring on translation word graphs we will obtain a more significant improvement in translation quality .","claim_evidence":"by performing a rescoring on translation word graphs we will obtain a more significant improvement in translation quality"},{"claim_score":-0.7129212,"evidence_score":-0.29616413,"text":"For the future we plan to investigate more refined feature selection methods in order to make the maximum entropy models smaller and bettergeneralizing ."},{"claim_score":-0.61481518,"evidence_score":-0.20026278,"text":"In addition , we want to investigate more syntactic , semantic features and to include features that go beyond sentence boundaries ."}]}