[
    {
        "claim_score": -0.095077808, 
        "evidence": "We achieved best results when the model training data , MT tuning set , and MT evaluation set con The bottom category includes all lexical items that the decoder could produce in a translation of the source .", 
        "evidence_score": 0.57477084, 
        "text": "We achieved best results when the model training data , MT tuning set , and MT evaluation set con The bottom category includes all lexical items that the decoder could produce in a translation of the source ."
    }, 
    {
        "claim_score": -0.92152825, 
        "evidence": "One potential avenue of future work would be to adapt our component models to new genres by self-training them on the target side of a large bitext .10 To focus on possibly inflected word forms , we excluded numbers and punctuation from this analysis .11 The annotator was the first author .", 
        "evidence_score": 0.088445479, 
        "text": "One potential avenue of future work would be to adapt our component models to new genres by self-training them on the target side of a large bitext .10 To focus on possibly inflected word forms , we excluded numbers and punctuation from this analysis .11 The annotator was the first author ."
    }, 
    {
        "claim_score": -2.7820836, 
        "evidence": "( 1 ) .", 
        "evidence_score": 0.0031156679, 
        "text": "( 1 ) ."
    }
]