{"document":[{"claim_score":-0.95657012,"evidence":"Statistical machine translation systems are usually trained on a large amount of bilingual sentence pairs and translate one sentence at a time , ignoring document-level information .","evidence_score":0.2237554,"text":"Statistical machine translation systems are usually trained on a large amount of bilingual sentence pairs and translate one sentence at a time , ignoring document-level information ."},{"claim_score":-1.0220382,"evidence_score":-0.21357352,"text":"In this paper , we propose a cache-based approach to document-level translation ."},{"claim_score":-0.26411051,"evidence_score":-0.57353415,"text":"Since caches mainly depend on relevant data to supervise subsequent decisions , it is critical to fill the caches with highly-relevant data of a reasonable size ."},{"claim_score":-0.95716678,"evidence_score":-0.21649466,"text":"In this paper , we present three kinds of caches to store relevant document-level information : 1 ) a dynamic cache , which stores bilingual phrase pairs from the best translation hypotheses of previous sentences in the test document ; 2 ) a static cache , which stores relevant bilingual phrase pairs extracted from similar bilingual document pairs ( i.e. source documents similar to the test document and their corresponding target documents ) in the training parallel corpus ; 3 ) a topic cache , which stores the target-side topic words related with the test document in the source-side ."},{"claim_score":-1.099675,"evidence":"In particular , three new features are designed to explore various kinds of document-level information in above three kinds of caches .","evidence_score":0.094788654,"text":"In particular , three new features are designed to explore various kinds of document-level information in above three kinds of caches ."},{"claim_score":-0.28377832,"evidence":"Evaluation shows the effectiveness of our cache-based approach to document-level translation with the performance improvement of 0.81 in BLUE score over Moses .","evidence_score":0.02488721,"text":"Evaluation shows the effectiveness of our cache-based approach to document-level translation with the performance improvement of 0.81 in BLUE score over Moses ."},{"claim_score":-0.91024226,"evidence_score":-1.084702,"text":"Especially , detailed analysis and discussion are presented to give new insights to document-level translation ."},{"claim_score":0.15166369,"evidence_score":-0.47341099,"claim":"During last decadetremendous work has been done to improve the quality of statistical machine * Corresponding author","text":"During last decade , tremendous work has been done to improve the quality of statistical machine * Corresponding author ."},{"claim_score":-2.0383968,"evidence_score":-1.1298469,"text":"translation ( SMT ) systems ."},{"claim_score":-0.93120174,"evidence_score":-1.223133,"text":"However , there is still a huge performance gap between the state-of-theart SMT systems and human translators ."},{"claim_score":-1.3764063,"evidence_score":-0.055325833,"text":"Bond ( 2002 ) suggested nine ways to improve machine translation by imitating the best practices of human translators ( Nida , 1964 ) , with parsing the entire document before translation as the first priority ."},{"claim_score":-0.16909103,"evidence_score":-0.78259217,"text":"However , most SMT systems still treat parallel corpora as a list of independent sentence-pairs and ignore document-level information ."},{"claim_score":-0.24407675,"evidence_score":-0.1579147,"text":"Document-level information can and should be used to help document-level machine translation ."},{"claim_score":0.29930991,"evidence_score":-0.66644488,"claim":"the topic of a document can help choose specific translation candidatesphrases and even sentences may be rather ambiguous and thus difficult to understand","text":"At least , the topic of a document can help choose specific translation candidates , since when taken out of the context from their document , some words , phrases and even sentences may be rather ambiguous and thus difficult to understand ."},{"claim_score":-0.81715457,"evidence_score":-0.38336158,"text":"Another advantage of document-level machine translation is its ability in keeping a consistent translation ."},{"claim_score":-0.28811229,"evidence_score":-0.68692212,"text":"However , document-level translation has drawn little attention from the SMT research community ."},{"claim_score":-1.4943761,"evidence_score":-0.70423198,"text":"The reasons are manifold ."},{"claim_score":-1.1409042,"evidence_score":-0.49722593,"text":"First of all , most of parallel corpora lack the annotation of document boundaries ( Tam , 2007 ) ."},{"claim_score":-0.7045505,"evidence_score":-0.24020824,"text":"Secondly , although it is easy to incorporate a new feature into the classical log-linear model ( Och , 2003 ) , it is difficult to capture document-level information and model it via some simple features ."},{"claim_score":0.12734456,"evidence_score":-0.41130716,"claim":"human translators tend to have flexible expressions in order to avoid producing monotonous texts","text":"Thirdly , reference translations of a test document written by human translators tend to have flexible expressions in order to avoid producing monotonous texts ."},{"claim_score":-1.7626631,"evidence_score":-0.84450505,"text":"This makes the evaluation of document-level SMT systems extremely difficult ."},{"claim_score":-0.24608801,"evidence":"Tiedemann ( 2010 ) showed that the repetition and consistency are very important when modeling natural language and translation .","evidence_score":0.33507205,"text":"Tiedemann ( 2010 ) showed that the repetition and consistency are very important when modeling natural language and translation ."},{"claim_score":-1.7452712,"evidence":"He proposed to employ cache-based language and translation models in a phrase-based SMT system for domain 909 Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing , pages 909 -- 919 , Edinburgh , Scotland , UK , July 27 -- 31 , 2011 .","evidence_score":0.083605519,"text":"He proposed to employ cache-based language and translation models in a phrase-based SMT system for domain 909 Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing , pages 909 -- 919 , Edinburgh , Scotland , UK , July 27 -- 31 , 2011 ."},{"claim_score":-1.5009642,"evidence_score":-0.10324304,"text":"Qc 2011 Association for Computational Linguistics adaptation ."},{"claim_score":-0.60334449,"evidence_score":-0.47735946,"text":"Especially , the cache in the translation model dynamically grows up by adding bilingual phrase pairs from the best translation hypotheses of previous sentences ."},{"claim_score":0.61770125,"evidence_score":-0.26519557,"claim":"","text":"One problem with the dynamic cache is that those initial sentences in a test document may not benefit from the dynamic cache ."},{"claim_score":0.60172184,"evidence_score":-0.79172126,"claim":"the dynamic cache may be prone to noise and cause error propagation","text":"Another problem is that the dynamic cache may be prone to noise and cause error propagation ."},{"claim_score":-1.4449211,"evidence_score":-0.75245289,"text":"This explains why the dynamic cache fails to much improve the performance ."},{"claim_score":-1.4617414,"evidence_score":-0.7203177,"text":"This paper proposes a cache-based approach for document-level SMT using a static cache and a dynamic cache ."},{"claim_score":-1.4590517,"evidence_score":-0.50210674,"text":"While such a approach applies to both phrase-based and syntax-based SMT , this paper focuses on phrase-based SMT ."},{"claim_score":-0.7450104,"evidence_score":-0.47962293,"text":"In particular , the static cache is employed to store relevant bilingual phrase pairs extracted from similar bilingual document pairs ( i.e. source documents similar to the test document and their target counterparts ) in the training parallel corpus while the dynamic cache is employed to store bilingual phrase pairs from the best translation hypotheses of previous sentences in the test document ."},{"claim_score":-0.85932444,"evidence_score":-0.58256972,"text":"In this way , our cache-based approach can provide useful data at the beginning of the translation process via the static cache ."},{"claim_score":0.047200799,"evidence_score":-0.53592699,"claim":"the translation process continues , the dynamic cache grows and contributes more and more to the translation of subsequent sentences","text":"As the translation process continues , the dynamic cache grows and contributes more and more to the translation of subsequent sentences ."},{"claim_score":0.18410581,"evidence_score":-0.30388559,"claim":"parallel corpus is simple : a human translator often collects similar bilingual document pairs to help translation","text":"Our motivation to employ similar bilingual document pairs in the training parallel corpus is simple : a human translator often collects similar bilingual document pairs to help translation ."},{"claim_score":-0.65571908,"evidence_score":-0.98935261,"text":"If there are translation pairs of sentences/phrases/words in similar bilingual document pairs , this makes the translation much easier ."},{"claim_score":-1.4306043,"evidence_score":-0.76020616,"text":"Given a test document , our approach imitates this procedure by first retrieving similar bilingual document pairs from the training parallel corpus , which has often been applied in IR-based adaptation of SMT systems ( Zhao et al. 2004 ; Hildebrand et al. 2005 ; Lu et al. 2007 ) and then extracting bilingual phrase pairs from similar bilingual document pairs to store them in a static cache ."},{"claim_score":-0.8887267,"evidence_score":-1.0871413,"text":"However , such a cache-based approach may in troduce many noisy/unnecessary bilingual phrase pairs in both the static and dynamic caches ."},{"claim_score":-0.54009615,"evidence":"In order to resolve this problem , this paper employs a topic model to weaken those noisy/unnecessary bilingual phrase pairs by recommending the decoder to choose most likely phrase pairs according to the topic words extracted from the target-side text of similar bilingual document pairs .","evidence_score":0.12404175,"text":"In order to resolve this problem , this paper employs a topic model to weaken those noisy/unnecessary bilingual phrase pairs by recommending the decoder to choose most likely phrase pairs according to the topic words extracted from the target-side text of similar bilingual document pairs ."},{"claim_score":-0.46805528,"evidence_score":-0.60773695,"text":"Just like a human translator , even with a big bilingual dictionary , is often confused when he meets a source phrase which corresponds to several possible translations ."},{"claim_score":-0.841789,"evidence_score":-0.10211177,"text":"In this case , some topic words can help reduce the perplexity ."},{"claim_score":-1.9115581,"evidence_score":-0.40588745,"text":"In this paper , the topic words are stored in a topic cache ."},{"claim_score":-1.0110309,"evidence_score":-0.75611032,"text":"In some sense , it has the similar effect of employing an adaptive language model with the advantage of avoiding the interpolation of a global language model with a specific domain language model ."},{"claim_score":-1.220283,"evidence_score":-0.94945826,"text":"The rest of this paper is organized as follows ."},{"claim_score":-1.367886,"evidence_score":-0.43420182,"text":"Section 2 reviews the related work ."},{"claim_score":-1.7185856,"evidence":"Section 3 presents our cache-based approach to documentlevel SMT .","evidence_score":0.034319031,"text":"Section 3 presents our cache-based approach to documentlevel SMT ."},{"claim_score":-1.4401478,"evidence_score":-0.48969792,"text":"Section 4 presents the experimental results ."},{"claim_score":-1.6328436,"evidence_score":-0.3465369,"text":"Session 5 gives new insights on cachebased document-level translation ."},{"claim_score":-2.0886814,"evidence_score":-0.089273319,"text":"Finally , we conclude this paper in Section 6 ."},{"claim_score":0.45667013,"evidence":"2 We have shown that our cache-based approach significantly improves the performance with the help of various caches , such as the dynamic , static and topic caches , although the cache-based ap-proach may introduce some negative impact onBLEU scores for certain documents.In the future , we will further explore how to re-flect document divergence during training and dynamically adjust cache weights according to different documents.There are many useful components in trainingdocuments , such as named entity , event and coreference .","evidence_score":0.093925871,"text":"2 We have shown that our cache-based approach significantly improves the performance with the help of various caches , such as the dynamic , static and topic caches , although the cache-based ap-proach may introduce some negative impact onBLEU scores for certain documents.In the future , we will further explore how to re-flect document divergence during training and dynamically adjust cache weights according to different documents.There are many useful components in trainingdocuments , such as named entity , event and coreference .","claim_evidence":"our cache-based approach significantly improves the performance with the help of various cachescache-based ap-proach may introduce some negative impact onBLEU scores for certain documents.In the futurehow to re-flect document divergence during training and dynamically adjust cache weights according to different documents.There are many useful components in trainingdocuments"},{"claim_score":-1.9494607,"evidence_score":-0.18263174,"text":"In this experiment , we only adopt the flat data in our cache ."},{"claim_score":-0.40815037,"evidence_score":-0.92561218,"text":"However , the structured data may improve the correctness of matching and thus effectively avoid noise ."},{"claim_score":-0.44813658,"evidence_score":-0.026466673,"text":"We will explore more effective ways to pick up various kinds of useful information from the training parallel corpus to expand our cache-based approach ."},{"claim_score":-0.98814187,"evidence_score":-0.11680919,"text":"Besides , we will resort to comparable corpora to enlarge our cachebased approach to document-level SMT ."}]}