<?xml version="1.0" encoding="UTF-8"?><document><sentence><claim_score>0.53262469</claim_score><evidence_score>-0.080221324</evidence_score><text>Abstract The ability of human visual system to detect visual saliency is extraordinarily fast and reliable .</text>
<claim> Abstract The ability of human visual system to detect visual saliency is extraordinarily fast and reliable</claim>
</sentence>
<sentence><claim_score>-0.67526725</claim_score><evidence_score>-0.49980271</evidence_score><text>However , computational modeling of this basic intelligent behavior still remains a challenge .</text>
<not_argumentative> However , computational modeling of this basic intelligent behavior still remains a challenge .</not_argumentative>
</sentence>
<sentence><claim_score>-1.6364552</claim_score><evidence_score>-1.0800732</evidence_score><text>This paper presents a simple method for the visual saliency detection .</text>
<not_argumentative> This paper presents a simple method for the visual saliency detection .</not_argumentative>
</sentence>
<sentence><claim_score>-0.59967247</claim_score><evidence_score>-0.99674598</evidence_score><text>Our model is independent of features , categories , or other forms of prior knowledge of the objects .</text>
<not_argumentative> Our model is independent of features , categories , or other forms of prior knowledge of the objects .</not_argumentative>
</sentence>
<sentence><claim_score>-0.5129713</claim_score><evidence_score>-0.19870677</evidence_score><text>By analyzing the log-spectrum of an input image , we extract the spectral residual of an image in spectral domain , and propose a fast method to construct the corresponding saliency map in spatial domain .</text>
<not_argumentative> By analyzing the log-spectrum of an input image , we extract the spectral residual of an image in spectral domain , and propose a fast method to construct the corresponding saliency map in spatial domain .</not_argumentative>
</sentence>
<sentence><claim_score>-1.562555</claim_score><evidence_score>-0.98110641</evidence_score><text>We test this model on both natural pictures and artificial images such as psychological patterns .</text>
<not_argumentative> We test this model on both natural pictures and artificial images such as psychological patterns .</not_argumentative>
</sentence>
<sentence><claim_score>-1.2098323</claim_score><evidence_score>-0.096461073</evidence_score><text>The result indicate fast and robust saliency detection of our method .</text>
<not_argumentative> The result indicate fast and robust saliency detection of our method .</not_argumentative>
</sentence>
<sentence><claim_score>-0.90142102</claim_score><evidence_score>-0.040503836</evidence_score><text>Discussion We proposed a method for general purpose object detection .</text>
<not_argumentative> Discussion We proposed a method for general purpose object detection .</not_argumentative>
</sentence>
<sentence><claim_score>-1.8388009</claim_score><evidence_score>-1.5407075</evidence_score><text>This method is based on the log spectra representation of images .</text>
<not_argumentative> This method is based on the log spectra representation of images .</not_argumentative>
</sentence>
<sentence><claim_score>-0.41122378</claim_score><evidence_score>-0.64077799</evidence_score><text>Our major contribution is the discovery of spectral residual and its general ability to detect proto-objects .</text>
<not_argumentative> Our major contribution is the discovery of spectral residual and its general ability to detect proto-objects .</not_argumentative>
</sentence>
<sentence><claim_score>-2.2511979</claim_score><evidence_score>-0.31839587</evidence_score><text>5.1 .</text>
<not_argumentative> 5.1 .</not_argumentative>
</sentence>
<sentence><claim_score>-0.88513749</claim_score><evidence_score>-0.54844305</evidence_score><text>The prospect of spectral residual approach One of the advantages of the spectral residual approach is its generality .</text>
<not_argumentative> The prospect of spectral residual approach One of the advantages of the spectral residual approach is its generality .</not_argumentative>
</sentence>
<sentence><claim_score>-1.212442</claim_score><evidence_score>-0.88289867</evidence_score><text>The prior knowledge required for saliency detection is not necessary in our system .</text>
<not_argumentative> The prior knowledge required for saliency detection is not necessary in our system .</not_argumentative>
</sentence>
<sentence><claim_score>-0.86577199</claim_score><evidence_score>-0.57219706</evidence_score><text>In addition , this all-in-one definition of saliency covers unknown features such as `` curve '' in Fig. 9 .</text>
<not_argumentative> In addition , this all-in-one definition of saliency covers unknown features such as `` curve '' in Fig. 9 .</not_argumentative>
</sentence>
<sentence><claim_score>-0.87300896</claim_score><evidence_score>-1.1663974</evidence_score><text>Also , the spectral residual resolves the problem of weighting features from different channels ( for example , shape , texture , and orientations ) .</text>
<not_argumentative> Also , the spectral residual resolves the problem of weighting features from different channels ( for example , shape , texture , and orientations ) .</not_argumentative>
</sentence>
<sentence><claim_score>-0.64644563</claim_score><evidence_score>-0.7160966</evidence_score><text>The result of our system , in contrast with its simple implementation , is demonstrated effective .</text>
<not_argumentative> The result of our system , in contrast with its simple implementation , is demonstrated effective .</not_argumentative>
</sentence>
<sentence><claim_score>-0.74460397</claim_score><evidence_score>0.45537841</evidence_score><text>Finally , compared with other detection algorithms , the computational consumption of our method is extremely parsimonious , providing a promising solution to real time systems .</text>
<evidence> Finally , compared with other detection algorithms , the computational consumption of our method is extremely parsimonious , providing a promising solution to real time systems .</evidence>
</sentence>
<sentence><claim_score>-2.4600702</claim_score><evidence_score>0.79140545</evidence_score><text>5.2 .</text>
<evidence> 5.2 .</evidence>
</sentence>
<sentence><claim_score>0.41691822</claim_score><evidence_score>-0.59273663</evidence_score><text>Further work Is the striking similarities of our results and performance of human visual system , especially , the response to psychological patterns , all comes in a coincidence , or if there is biological implications of the human visual system and the spectral residual ?</text>
<claim> Further work Is the striking similarities of our results and performance of human visual system</claim>
<claim> the response to psychological patterns , all comes in a coincidence</claim>
<claim> there is biological implications of the human visual system and the spectral residual</claim>
</sentence>
<sentence><claim_score>-0.31547171</claim_score><evidence_score>0.24608736</evidence_score><text>It has been reported that different objects with similar frequency spectra interfere with each other [ 2 ] .</text>
<evidence> It has been reported that different objects with similar frequency spectra interfere with each other [ 2 ] .</evidence>
</sentence>
<sentence><claim_score>0.81444574</claim_score><evidence_score>0.82658181</evidence_score><text>More recent studies also indicate that a visual target takes more time to be identified when the spectrum of background is carefully tuned to mask the spectrum of the foreground [ 28 ] .</text>
<claim_evidence> a visual target takes more time to be identified when the spectrum of background is carefully tuned to mask the spectrum of the foreground [ 28 ]</claim_evidence>
<evidence> More recent studies also indicate that a visual target takes more time to be identified when the spectrum of background is carefully tuned to mask the spectrum of the foreground [ 28 ] .</evidence>
</sentence>
<sentence><claim_score>-0.35898451</claim_score><evidence_score>-1.2303305</evidence_score><text>More work is required to discover the spectral properties of early vision .</text>
<not_argumentative> More work is required to discover the spectral properties of early vision .</not_argumentative>
</sentence>
<sentence><claim_score>-2.1460186</claim_score><evidence_score>-0.80660926</evidence_score><text>In this paper , our discussion is limited to static images .</text>
<not_argumentative> In this paper , our discussion is limited to static images .</not_argumentative>
</sentence>
<sentence><claim_score>-0.52490122</claim_score><evidence_score>-0.038162295</evidence_score><text>Although it is possible to compute the saliency map for each Figure 8 .</text>
<not_argumentative> Although it is possible to compute the saliency map for each Figure 8 .</not_argumentative>
</sentence>
<sentence><claim_score>-0.61992273</claim_score><evidence_score>-0.12389886</evidence_score><text>The result of our method in comparison with Itti 's method and the result of human labelers .</text>
<not_argumentative> The result of our method in comparison with Itti 's method and the result of human labelers .</not_argumentative>
</sentence>
<sentence><claim_score>-1.1505094</claim_score><evidence_score>-0.96857574</evidence_score><text>In each group , we present 1 ) the input image , 2 ) saliency map generated by spectral residual , 3 ) saliency map Q generated by Itti 's method , and 4 ) labeled map of the four labelers .</text>
<not_argumentative> In each group , we present 1 ) the input image , 2 ) saliency map generated by spectral residual , 3 ) saliency map Q generated by Itti 's method , and 4 ) labeled map of the four labelers .</not_argumentative>
</sentence>
<sentence><claim_score>-1.5159457</claim_score><evidence_score>-1.0965602</evidence_score><text>In the labeled map , the white region represents the hit map , where Ok ( x ) = 1 ; the black region represents the false alarm map , where Q ( 1 − Ok ( x ) ) = 0 ; and the gray region is selected by some labelers but rejected by others .</text>
<not_argumentative> In the labeled map , the white region represents the hit map , where Ok ( x ) = 1 ; the black region represents the false alarm map , where Q ( 1 − Ok ( x ) ) = 0 ; and the gray region is selected by some labelers but rejected by others .</not_argumentative>
</sentence>
<sentence><claim_score>0.1265599</claim_score><evidence_score>0.1272755</evidence_score><text>frames of a video sequence without considering their continuity , incorporating motion features will greatly extend the application of our method .</text>
<claim_evidence> frames of a video sequence without considering their continuity , incorporating motion features will greatly extend the application of our method</claim_evidence>
<evidence> frames of a video sequence without considering their continuity , incorporating motion features will greatly extend the application of our method .</evidence>
</sentence>
<sentence><claim_score>-0.89435627</claim_score><evidence_score>-0.46194325</evidence_score><text>Due to the particularity of motion features , a unified model of features has not yet been proposed .</text>
<not_argumentative> Due to the particularity of motion features , a unified model of features has not yet been proposed .</not_argumentative>
</sentence>
<sentence><claim_score>-0.72586926</claim_score><evidence_score>-0.12298225</evidence_score><text>Yet , we are glad to see that efforts have been made in incorporating motion into a general framework of features [ 16 ] .</text>
<not_argumentative> Yet , we are glad to see that efforts have been made in incorporating motion into a general framework of features [ 16 ] .</not_argumentative>
</sentence>
<sentence><claim_score>-1.8931494</claim_score><evidence_score>-0.64864356</evidence_score><text>Another potential work is to cooperate our method with segmentation techniques .</text>
<not_argumentative> Another potential work is to cooperate our method with segmentation techniques .</not_argumentative>
</sentence>
<sentence><claim_score>-0.58365626</claim_score><evidence_score>-0.83479277</evidence_score><text>Segmentation is an independent area of research whose primary goal is to separate borders .</text>
<not_argumentative> Segmentation is an independent area of research whose primary goal is to separate borders .</not_argumentative>
</sentence>
<sentence><claim_score>-1.4412728</claim_score><evidence_score>0.099769045</evidence_score><text>In comparison , our method overlooked the spatial homogeneity of an object .</text>
<evidence> In comparison , our method overlooked the spatial homogeneity of an object .</evidence>
</sentence>
<sentence><claim_score>-1.2584336</claim_score><evidence_score>-0.42700707</evidence_score><text>For instance , in the last example of Fig. 8 , the poloists and their horses are separated .</text>
<not_argumentative> For instance , in the last example of Fig. 8 , the poloists and their horses are separated .</not_argumentative>
</sentence>
<sentence><claim_score>-0.19227883</claim_score><evidence_score>-0.19107696</evidence_score><text>In order to achieve the general purpose object detection , further efforts should be done to delimit a clear border of an object .</text>
<not_argumentative> In order to achieve the general purpose object detection , further efforts should be done to delimit a clear border of an object .</not_argumentative>
</sentence>
<sentence><claim_score>-2.5165041</claim_score><evidence_score>0.79356372</evidence_score><text>6 .</text>
<evidence> 6 .</evidence>
</sentence>
<sentence><claim_score>-1.8809104</claim_score><evidence_score>-0.26884682</evidence_score><text>Acknowledgement The work was the National High-Tech Research Program of China ( Grant No. 252006AA01Z125 ) and supported by the National Basic Research Program of China ( Grant No. 2005CB724301 ) .</text>
<not_argumentative> Acknowledgement The work was the National High-Tech Research Program of China ( Grant No. 252006AA01Z125 ) and supported by the National Basic Research Program of China ( Grant No. 2005CB724301 ) .</not_argumentative>
</sentence>
<sentence><claim_score>-1.4694742</claim_score><evidence_score>-0.11649122</evidence_score><text>The first author would like to thank Deli Zhao , Dirk Walther , and Yuandong Tian for their valuable discussions .</text>
<not_argumentative> The first author would like to thank Deli Zhao , Dirk Walther , and Yuandong Tian for their valuable discussions .</not_argumentative>
</sentence>
</document>