[
    {
        "claim_evidence": "the proposed methodology can be beneficial for both resource developers evaluating their output as well as inference system developers wanting to assess the quality of existing resources", 
        "claim_score": 0.23531333, 
        "evidence": "Using the CrowdFlower forms we provide with this paper , the proposed methodology can be beneficial for both resource developers evaluating their output as well as inference system developers wanting to assess the quality of existing resources", 
        "evidence_score": 0.083844166, 
        "text": "Using the CrowdFlower forms we provide with this paper , the proposed methodology can be beneficial for both resource developers evaluating their output as well as inference system developers wanting to assess the quality of existing resources"
    }, 
    {
        "claim": "The importance of inference rules to semantic applications has long been recognized and extensive work has been carried out to automatically acquire inference-rule resources", 
        "claim_score": 0.18362043, 
        "evidence_score": -0.44493067, 
        "text": "The importance of inference rules to semantic applications has long been recognized and extensive work has been carried out to automatically acquire inference-rule resources ."
    }, 
    {
        "claim_evidence": "our method produces a large amount of annotations with high inter-annotator agreement for a low cost at a short period of time", 
        "claim_score": 0.068145064, 
        "evidence": "We show that our method produces a large amount of annotations with high inter-annotator agreement for a low cost at a short period of time , without requiring training expert annotators .", 
        "evidence_score": 0.55559261, 
        "text": "We show that our method produces a large amount of annotations with high inter-annotator agreement for a low cost at a short period of time , without requiring training expert annotators ."
    }, 
    {
        "claim_evidence": "able to take advantage of crowdsourcing services to replace trained expert annotators , resulting in good quality large scale annotations , for reasonable time and cost", 
        "claim_score": 0.034573809, 
        "evidence": "We have shown that by simplifying the previously-proposed instance-based evaluation framework we are able to take advantage of crowdsourcing services to replace trained expert annotators , resulting in good quality large scale annotations , for reasonable time and cost .", 
        "evidence_score": 0.24410967, 
        "text": "We have shown that by simplifying the previously-proposed instance-based evaluation framework we are able to take advantage of crowdsourcing services to replace trained expert annotators , resulting in good quality large scale annotations , for reasonable time and cost ."
    }
]