{"document":[{"claim_score":-0.42964526,"evidence_score":-0.80258257,"text":"Typically , the lexicon models used in statistical machine translation systems do not include any kind of linguistic or contextual information , which often leads to problems in performing a correct word sense disambiguation ."},{"claim_score":-0.64988415,"evidence_score":-0.63363005,"text":"One way to deal with this problem within the statistical framework is to use maximum entropy methods ."},{"claim_score":-1.7279627,"evidence_score":-0.25892927,"text":"In this paper , we present how to use this type of information within a statistical machine translation system ."},{"claim_score":0.22870353,"evidence":"We show that it is possible to significantly decrease training and test corpus perplexity of the translation models .","evidence_score":1.1620379,"text":"We show that it is possible to significantly decrease training and test corpus perplexity of the translation models .","claim_evidence":"it is possible to significantly decrease training and test corpus perplexity of the translation models"},{"claim_score":-0.25432741,"evidence":"In addition , we perform a rescoring of-Best lists using our maximum entropy model and thereby yield an improvement in translation quality .","evidence_score":0.64262339,"text":"In addition , we perform a rescoring of-Best lists using our maximum entropy model and thereby yield an improvement in translation quality ."},{"claim_score":-1.3918416,"evidence_score":-0.43182525,"text":"Experimental results are presented on the so-called Verbmobil Task ."},{"claim_score":-1.2666691,"evidence_score":-1.0050515,"text":"Typically , the lexicon models used in statistical machine translation systems are only single-word based , that is one word in the source language corresponds to only one word in the target language ."},{"claim_score":-0.80289224,"evidence_score":-0.2488423,"text":"Those lexicon models lack from context information that can be extracted from the same parallel corpus ."},{"claim_score":-0.7038671,"evidence":"This additional information could be : Simple context information : information of the words surrounding the word pair ; Syntactic information : part-of-speech information , syntactic constituent , sentence Semantic information : disambiguation information ( e.g.from WordNet currentspeech or dialog act .","evidence_score":0.33505297,"text":"This additional information could be : Simple context information : information of the words surrounding the word pair ; Syntactic information : part-of-speech information , syntactic constituent , sentence Semantic information : disambiguation information ( e.g.from WordNet currentspeech or dialog act ."},{"claim_score":-1.9014649,"evidence_score":-0.47958984,"text":"To include this additional information within the statistical framework we use the maximum entropy approach ."},{"claim_score":-0.73906031,"evidence_score":-0.66402152,"text":"This approach has been applied in natural language processing to a variety of tasks Berger et al 1996 ) applies this approach to the so-called IBM Candide system to build context dependent models , compute automatic sentence splitting and to improve word reordering in translation ."},{"claim_score":-1.6426005,"evidence_score":-0.85427246,"text":"Similar techniques are used in ( Papineni et al 1996 ; Papineni et al 1998 ) for socalled direct translation models instead of those proposed in ( Brown et al 1993 Foster , 2000 ) describes two methods for incorporating information about the relative position of bilingual word pairs into a maximum entropy translation model ."},{"claim_score":-2.0669844,"evidence":"Other authors have applied this approach to language modeling ( Rosenfeld , 1996 ; Martin et al 1999 ; Peters and Klakow , 1999 A short review of the maximum entropy approach is outlined in Section 3 .","evidence_score":0.033972985,"text":"Other authors have applied this approach to language modeling ( Rosenfeld , 1996 ; Martin et al 1999 ; Peters and Klakow , 1999 A short review of the maximum entropy approach is outlined in Section 3 ."},{"claim_score":-1.3891112,"evidence_score":-0.08059383,"text":"We have developed refined lexicon models for statistical machine translation by using maximum entropy models ."},{"claim_score":-0.81306344,"evidence":"We have been able to obtain a significant better test corpus perplexity and also a slight improvement in translation quality .","evidence_score":0.4361579,"text":"We have been able to obtain a significant better test corpus perplexity and also a slight improvement in translation quality ."},{"claim_score":0.16814659,"evidence":"We believe that by performing a rescoring on translation word graphs we will obtain a more significant improvement in translation quality .","evidence_score":0.63124473,"text":"We believe that by performing a rescoring on translation word graphs we will obtain a more significant improvement in translation quality .","claim_evidence":"by performing a rescoring on translation word graphs we will obtain a more significant improvement in translation quality"},{"claim_score":-0.7129212,"evidence_score":-0.29616413,"text":"For the future we plan to investigate more refined feature selection methods in order to make the maximum entropy models smaller and bettergeneralizing ."},{"claim_score":-0.41090779,"evidence_score":-0.31227653,"text":"In addition , we want to investigate more syntactic , semantic features and to include features that go beyond sentence boundaries"}]}