[
    {
        "claim": "training data can be avoided", 
        "claim_score": 0.78874812, 
        "evidence_score": -0.12960608, 
        "text": "Note that for certain tasks , the performance of a web baseline model might actually be suffi cient , so that the effort of constructing a sophisticated supervised model and annotating the necessary training data can be avoided ."
    }, 
    {
        "claim": "web counts can be used to approximate bigram frequencies , and thus should be useful for a wide variety of NLP tasks", 
        "claim_score": 0.69166641, 
        "evidence_score": -0.25163295, 
        "text": "Previous work demonstrated that web counts can be used to approximate bigram frequencies , and thus should be useful for a wide variety of NLP tasks ."
    }, 
    {
        "claim_evidence": "Note that for all the tasksthe best performance in the literature was obtained by supervised models that have access not only to simple bigramunsupervised web-based models are compared against supervised methods that employ a wide variety of featureshaving access to linguistic information makes up for the lack of vast amounts of data", 
        "claim_score": 0.63798411, 
        "evidence": "Note that for all the tasks we investigated , the best performance in the literature was obtained by supervised models that have access not only to simple bigram or trigram frequencies , but also to linguistic information such as part-of-speech tags , semantic restrictions , or context ( or a thesaurus , in the case of Lauers models When unsupervised web-based models are compared against supervised methods that employ a wide variety of features , we observe that having access to linguistic information makes up for the lack of vast amounts of data .", 
        "evidence_score": 0.00076697411, 
        "text": "Note that for all the tasks we investigated , the best performance in the literature was obtained by supervised models that have access not only to simple bigram or trigram frequencies , but also to linguistic information such as part-of-speech tags , semantic restrictions , or context ( or a thesaurus , in the case of Lauers models When unsupervised web-based models are compared against supervised methods that employ a wide variety of features , we observe that having access to linguistic information makes up for the lack of vast amounts of data ."
    }, 
    {
        "claim": "Our results therefore indicate that large data setsthey are claimed to beweb-based models should be used as a new baseline for NLP tasks", 
        "claim_score": 0.49158791, 
        "evidence_score": -0.34645707, 
        "text": "Our results therefore indicate that large data sets such as those obtained from the web are not the panacea that they are claimed to be ( at least implicitly ) by authors such as Grefenstette and Keller and Lapata ( 2003 Rather , in our opinion , web-based models should be used as a new baseline for NLP tasks ."
    }, 
    {
        "claim_evidence": "models perform better when n-gram frequencies are obtained from the web rather than from a large corpus", 
        "claim_score": 0.28068486, 
        "evidence": "For the majority of tasks , we fi nd that simple , unsupervised models perform better when n-gram frequencies are obtained from the web rather than from a large corpus .", 
        "evidence_score": 0.061330178, 
        "text": "For the majority of tasks , we fi nd that simple , unsupervised models perform better when n-gram frequencies are obtained from the web rather than from a large corpus ."
    }, 
    {
        "claim_evidence": "web-based models should therefore be used as a baseline for", 
        "claim_score": 0.1234567, 
        "evidence": "We argue that web-based models should therefore be used as a baseline for , rather than an alternative to , standard models . .", 
        "evidence_score": 0.21147363, 
        "text": "We argue that web-based models should therefore be used as a baseline for , rather than an alternative to , standard models . ."
    }
]