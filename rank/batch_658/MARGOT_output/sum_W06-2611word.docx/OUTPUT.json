{"document":[{"claim_score":-1.3635466,"evidence_score":-0.80594637,"text":"Abstract This article describes a robust semantic parser that uses a broad knowledge base created by interconnecting three major resources : FrameNet , VerbNet and PropBank ."},{"claim_score":-0.61635874,"evidence_score":-0.59856803,"text":"The FrameNet corpus con tains the examples annotated with se mantic roles whereas the VerbNet lexi con provides the knowledge about the syntactic behavior of the verbs ."},{"claim_score":-1.5700189,"evidence_score":-0.14295138,"text":"We connect VerbNet and FrameNet by mapping the FrameNet frames to the VerbNet Intersective Levin classes ."},{"claim_score":-1.1413551,"evidence_score":-0.6334012,"text":"The PropBank corpus , which is tightly con nected to the VerbNet lexicon , is used to increase the verb coverage and also to test the effectiveness of our approach ."},{"claim_score":0.9255759,"evidence":"The results indicate that our model is an interesting step towards the design of free-text semantic parsers .","evidence_score":0.01132765,"text":"The results indicate that our model is an interesting step towards the design of free-text semantic parsers .","claim_evidence":"The results indicate that our model is an interesting step towards the design of free-text semantic parsers"},{"claim_score":-0.61128274,"evidence_score":-0.97324137,"text":"Introduction Introduction During the last years a noticeable effort has been devoted to the design of lexical resources that can provide the training ground for automatic semantic role labelers ."},{"claim_score":0.10758206,"evidence_score":-0.1198493,"claim":"they use during the learning stage","text":"Unfortunately , most of the systems developed until now are confined to the scope of the resource that they use during the learning stage ."},{"claim_score":-2.2946952,"evidence_score":-0.29968986,"text":"A very recent example in this sense was provided by the CONLL 2005 Shared Task on PropBank ( Kingsbury and Palmer , 2002 ) role labeling ( Carreras and MÃ rquez , 2005 ) ."},{"claim_score":-1.9222669,"evidence":"While the best F-measure recorded on a test set selected from the training corpus ( WSJ ) was 80percent , on the Brown corpus , the F-measure dropped below 70percent .","evidence_score":0.045008239,"text":"While the best F-measure recorded on a test set selected from the training corpus ( WSJ ) was 80percent , on the Brown corpus , the F-measure dropped below 70percent ."},{"claim_score":-1.379112,"evidence_score":-0.061627201,"text":"The most significant causes for this performance decay were highly ambiguous and unseen predicates ( i.e. predicates that do not have training examples , unseen in the training set ) ."},{"claim_score":-1.884419,"evidence_score":-0.29569437,"text":"On the FrameNet ( Johnson et al. , 2003 ) role labeling task , the Senseval-3 competition ( Litkowski , 2004 ) Conclusions"}]}