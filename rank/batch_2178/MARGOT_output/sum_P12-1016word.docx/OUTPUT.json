{"document":[{"claim_score":-2.7820836,"evidence":"( 1 ) .","evidence_score":0.0031156679,"text":"( 1 ) ."},{"claim_score":-1.2838804,"evidence_score":-0.2326292,"text":"_ -RCB- ... - ll ."},{"claim_score":-0.64869762,"evidence_score":-0.73737088,"text":"When automatically translating from a weakly inflected source language like English to a target language with richer grammatical features such as gender and dual number , the output commonly contains morpho-syntactic agreement errors ."},{"claim_score":-1.8940479,"evidence_score":-0.76580053,"text":"To address this issue , we present a target-side , class-based agreement model ."},{"claim_score":-1.2903846,"evidence_score":-1.0707368,"text":"Agreement is promoted by scoring a sequence of fine-grained morpho-syntactic classes that are predicted during decoding for each translation hypothesis ."},{"claim_score":-1.2852937,"evidence_score":-0.26081022,"text":"For English-to-Arabic translation , our model yields a +1.04 BLEU average improvement over a state-of-the-art baseline ."},{"claim_score":-0.54855054,"evidence_score":-1.2208609,"text":"The model does not require bitext or phrase table annotations and can be easily implemented as a feature in many phrase-based decoders ."},{"claim_score":-0.85374116,"evidence_score":-0.24883887,"text":"Our class-based agreement model improves translation quality by promoting local agreement , but with a minimal increase in decoding time and no additional storage requirements for the phrase table ."},{"claim_score":-0.95146403,"evidence_score":-0.90202637,"text":"The model can be implemented with a standard CRF package , trained on existing treebanks for many languages , and integrated easily with many MT feature APIs ."},{"claim_score":-0.095077808,"evidence":"We achieved best results when the model training data , MT tuning set , and MT evaluation set con The bottom category includes all lexical items that the decoder could produce in a translation of the source .","evidence_score":0.57477084,"text":"We achieved best results when the model training data , MT tuning set , and MT evaluation set con The bottom category includes all lexical items that the decoder could produce in a translation of the source ."},{"claim_score":-0.17262262,"evidence_score":-0.63170425,"text":"This large gap between the unigram recall of the actual translation output ( top ) and the lexical coverage of the phrase-based model ( bottom ) indicates that translation performance can be improved dramatically by altering the translation model through features such as ours , without expanding the search space of the decoder.mixed genre evaluation sets ."},{"claim_score":-0.26984325,"evidence_score":-0.2242196,"text":"In principle , our class-based model should be more robust to unseen word types and other phenomena that make non-newswire genres challenging ."},{"claim_score":0.30704379,"evidence_score":-0.18010181,"claim":"there is less morphology to score","text":"However , our analysis has shown that for Arabic , these genres typically contain more Latin script and transliterated words , and thus there is less morphology to score ."},{"claim_score":-0.92152825,"evidence":"One potential avenue of future work would be to adapt our component models to new genres by self-training them on the target side of a large bitext .10 To focus on possibly inflected word forms , we excluded numbers and punctuation from this analysis .11 The annotator was the first author .","evidence_score":0.088445479,"text":"One potential avenue of future work would be to adapt our component models to new genres by self-training them on the target side of a large bitext .10 To focus on possibly inflected word forms , we excluded numbers and punctuation from this analysis .11 The annotator was the first author ."}]}