{"document":[{"claim_score":-0.9227228,"evidence":"We present improvements to a greedy decoding algorithm for statistical machine translation that reduce its time complexity from at least cubic ( when applied na ¨ ıvely ) to practically linear time1 without sacrificing translation quality .","evidence_score":0.38153842,"text":"We present improvements to a greedy decoding algorithm for statistical machine translation that reduce its time complexity from at least cubic ( when applied na ¨ ıvely ) to practically linear time1 without sacrificing translation quality ."},{"claim_score":-0.27441496,"evidence":"We achieve this by integrating hypothesis evaluation into hypothesis creation , tiling improvements over the translation hypothesis at the end of each search iteration , and by imposing restrictions on the amount of word reordering during decoding .","evidence_score":0.0030233184,"text":"We achieve this by integrating hypothesis evaluation into hypothesis creation , tiling improvements over the translation hypothesis at the end of each search iteration , and by imposing restrictions on the amount of word reordering during decoding ."},{"claim_score":-1.4292324,"evidence_score":-0.076029861,"text":"In this paper , we have analyzed the complexity of the greedy decoding algorithm originally presented in Germann et al. ( 2001 ) and presented improvements that drastically reduce the decoder 's complexity and speed to practically linear time.Experimental data suggests a good correlation betweenG1 decoding anddecoding ( with 10 translations per input word con-sidered , a list of 498 candidates for INSERT , a maximum swap distance of 2 and a maximum swap segment size of 5 ) ."},{"claim_score":-0.87272239,"evidence_score":-0.058522963,"text":"The profiles shown are cumulative , so that the top curve reflects the total decoding time ."},{"claim_score":-1.00688,"evidence_score":-0.44508261,"text":"To put the times for decoding in perspective , the dashed line in the lower plot reflects the total decoding time in decoding ."},{"claim_score":-0.56878603,"evidence":"Operations not included in the figures consume so little time that their plots can not be discerned in the graphs .","evidence_score":0.1326544,"text":"Operations not included in the figures consume so little time that their plots can not be discerned in the graphs ."},{"claim_score":-2.0714592,"evidence":"The times shown are averages of 100 sentences each for length10 , 20 , , 80 .","evidence_score":0.31740742,"text":"The times shown are averages of 100 sentences each for length10 , 20 , , 80 ."},{"claim_score":-2.4967784,"evidence":"IBM Model 4 scores and the BLEU metric .","evidence_score":0.21729648,"text":"IBM Model 4 scores and the BLEU metric ."},{"claim_score":-0.60220886,"evidence":"The speed improvements discussed in this paper make multiple randomized searches per sentence feasible , leading to a faster and better decoder for machine translation with IBM Model 4.6","evidence_score":0.026806951,"text":"The speed improvements discussed in this paper make multiple randomized searches per sentence feasible , leading to a faster and better decoder for machine translation with IBM Model 4.6"}]}