{"document":[{"claim_score":-1.5808891,"evidence_score":-0.30355806,"text":"In this paper we study a set of problems that are of considerable importance to Statistical Machine Translation ( SMT ) but which have not been addressed satisfactorily by the SMT research community ."},{"claim_score":-0.89385607,"evidence_score":-0.62520956,"text":"Over the last decade , a variety of SMT algorithms have been built and empirically tested whereas little is known about the computational complexity of some of the fundamental problems of SMT ."},{"claim_score":-0.73367962,"evidence_score":-0.35895497,"text":"Our work aims at providing useful insights into the the computational complexity of those problems ."},{"claim_score":0.79625989,"evidence_score":-0.38175598,"claim":"1-2 are conceptuallythere exists aThe models are independent of the language pair and therefore , can be used to build a translation system for any language pair as long as a parallel corpus of texts is available for training","text":"We prove that while IBM Models 1-2 are conceptually and computationally simple , computations involving the higher ( and more useful ) models are hard.Since it is unlikely that there exists a poly-language 1 ( Tillman , 2001 Wang , 1997 Germann et al 2003 Udupa et al 2004 The models are independent of the language pair and therefore , can be used to build a translation system for any language pair as long as a parallel corpus of texts is available for training ."},{"claim_score":-1.1268489,"evidence_score":-0.96944618,"text":"Increasingly , parallel corpora are becoming available for many language pairs and SMT systems have been built for French-English , German-English , Arabic-English , Chinese-English , Hindi-English and other language pairs ( Brown et al 1993 AlOnaizan et al 1999 Udupa , 2004 In SMT , every English sentence e is considered as a translation of a given French sentence f withprobability P r ( f | e Therefore , the problem oftranslating f can be viewed as a problem of findingthe most probable translation of f : e argmax P r ( e | f argmax P r ( f | e ) P ."},{"claim_score":-1.4884782,"evidence":"enomial time solution for any of these hardeproblems ( unless P NP and P #P P our results highlight and justify the need for developing polynomial time approximations for these computations .","evidence_score":0.050937218,"text":"enomial time solution for any of these hardeproblems ( unless P NP and P #P P our results highlight and justify the need for developing polynomial time approximations for these computations ."},{"claim_score":-1.2225852,"evidence_score":-1.0679218,"text":"We also discuss some practical ways of dealing with complexity ."},{"claim_score":-0.95292493,"evidence_score":-0.94899828,"text":"Statistical Machine Translation is a data driven machine translation technique which uses probabilistic models of natural language for automatic The probability distributions P r ( f | e ) and P r are known as translation model and lan guage model respectively ."},{"claim_score":-0.50121899,"evidence_score":-0.07088342,"text":"In the classic work on SMT , Brown and his colleagues at IBM introduced the notion of alignment between a sentence f and its translation e and used it in the development of translation models ( Brown et al 1993 An alignment between f f1 fm and e e1 el is a many-to-one mapping a 1 m -RCB- -LCB- 0 l Thus , an alignment a between f and e associates the french word fj to the English word 2 The number of words of f mapped to ei by translation ( Brown et al 1993 Al-Onaizan et al 1999 The parameters of the models are estimated by iterative maximum-likelihood training on a large parallel corpus of natural language texts using the EM algorithm ( Brown et al 1993 The models are then used to decode , i.e. translate texts from the source language to the target eaj a is called the fertility of ei and is denoted by i Since P r ( f | e a P r ( f a | e equation 1 can 1 In this paper , we use French and English as the prototypical examples of source and target languages respectively ."},{"claim_score":-0.53967096,"evidence_score":-0.3430403,"text":"2 e0 is a special word called the null word and is used to account for those words in f that are not connected by a to any of the words of e. be rewritten as follows : e argmax P r ( f a | e ) P r.Relaxed Decoding Given the model parameters and a sentence f e determine the most probable translation and aalignment pair for f Brown and his colleagues developed a series of 5 translation models which have become to be known in the field of machine translation as IBM models ."},{"claim_score":-0.71618885,"evidence_score":-0.47216031,"text":"For a detailed introduction to IBM translation models , please see ( Brown et al 1993 In practice , models 3-5 are known to give good results and models 1-2 are used to seed the EM iterations of the higher models ."},{"claim_score":-1.2002498,"evidence_score":-0.50083146,"text":"IBM model 3 is the prototypical translation model and it models P r ( f a | e ) as follows e argmax P ( f a | e ) P ( e , a ) Viterbi Alignment computation finds applications not only in SMT but also in other areas of Natural Language Processing ( Wang , 1998 Marcu , 2002 Expectation Evaluation is the soul of parameter estimation ( Brown et al 1993 Al-Onaizan et al 1999 Conditional Probability computation is important in experimentally studying the concentration of the probability mass P ( f a | e ) n ( 0 l \\ l i = 1 n ( i | ei i !"},{"claim_score":-0.87108852,"evidence":"around the Viterbi alignment , i.e. in determining j = 1 tfj | eajdj : aj I = 0 d ( j | i , m the goodness of the Viterbi alignment in compar ison to the rest of the alignments.Decoding is an integral component of all SMT systems ( Wang , Table 1 : IBM Model 3 Here , n ( | e ) is the fertility model , t ( f | e ) is the lexicon model and d ( j | i , m is the distortion model .","evidence_score":0.088652321,"text":"around the Viterbi alignment , i.e. in determining j = 1 tfj | eajdj : aj I = 0 d ( j | i , m the goodness of the Viterbi alignment in compar ison to the rest of the alignments.Decoding is an integral component of all SMT systems ( Wang , Table 1 : IBM Model 3 Here , n ( | e ) is the fertility model , t ( f | e ) is the lexicon model and d ( j | i , m is the distortion model ."},{"claim_score":-0.75998875,"evidence_score":-0.13866561,"text":"The computational tasks involving IBM Models are the following : Viterbi Alignment Given the model parameters and a sentence pair ( f e determine the most probable alignment between f and e. a argmax P ( f a | e ) aExpectation Evaluation This forms the core of model training via the EM algorithm ."},{"claim_score":-1.0112341,"evidence_score":-0.55582948,"text":"Please see Section 2.3 for a description of the computational task involved in the EM iterations.Conditional Probability Given the model parameters and a sentence pair ( f e compute P ( f | e 1997 Tillman , 2000 Och et al 2001 Germann et al 2003 Udupa et al 2004 Exact Decoding is the original decoding problem as defined in ( Brown et al 1993 ) and Relaxed Decoding is the relaxation of the decoding problem typically used in practice ."},{"claim_score":-1.4431775,"evidence_score":-0.7992054,"text":"While several heuristics have been developed by practitioners of SMT for the computational tasks involving IBM models , not much is known about the computational complexity of these tasks ."},{"claim_score":-0.74043092,"evidence":"In their seminal paper on SMT , Brown and his colleagues highlighted the problems we face as we go from IBM Models 1-2 to 3-5 ( Brown et al 1993 ) 3 : As we progress from Model 1 to Model 5 , evaluating the expectations that gives us counts becomes increasingly difficult .","evidence_score":1.3606651,"text":"In their seminal paper on SMT , Brown and his colleagues highlighted the problems we face as we go from IBM Models 1-2 to 3-5 ( Brown et al 1993 ) 3 : As we progress from Model 1 to Model 5 , evaluating the expectations that gives us counts becomes increasingly difficult ."},{"claim_score":-0.81818718,"evidence_score":-0.51720914,"text":"In Models 3 and 4 , we must be content with approximate EM iterations because it is not feasible to carry out sums over all possible alignments for these models ."},{"claim_score":-0.82434541,"evidence":"In practice , we are never sure that we have found the Viterbi alignment .","evidence_score":0.32609188,"text":"In practice , we are never sure that we have found the Viterbi alignment ."},{"claim_score":-1.5584231,"evidence_score":-0.80988328,"text":"However , neither their work nor the subsequent P ( f | e aExact Decoding P ( f a | e ) research in SMT studied the computational complexity of these fundamental problems with the exception of the Decoding problem ."},{"claim_score":-0.32415006,"evidence":"In ( Knight , 1999 ) it was proved that the Exact Decoding prob Given the model parameters and a sentence f determine the most probable translation of f lem is NP-Hard when the language model is a bigram model .","evidence_score":0.40252992,"text":"In ( Knight , 1999 ) it was proved that the Exact Decoding prob Given the model parameters and a sentence f determine the most probable translation of f lem is NP-Hard when the language model is a bigram model ."},{"claim_score":-0.5131173,"evidence_score":-0.33403273,"text":"e argmax e P ( f a | e ) Pa Our results may be summarized as follows : 3 The emphasis is ours .1 ."},{"claim_score":-1.6479683,"evidence_score":-0.50480381,"text":"Viterbi Alignment computation is NP-Hard for IBM Models 3 , 4 , and 5 IBM models 3-5 are widely used in SMT ."},{"claim_score":-1.974557,"evidence_score":-1.3813783,"text":"The computational tasks discussed in this work form the backbone of all SMT systems that use IBM models ."},{"claim_score":-0.37130169,"evidence":"We believe that our results on the computational complexity of the tasks in SMT will result in a better understanding of these tasks from a theoretical perspective .","evidence_score":0.34797446,"text":"We believe that our results on the computational complexity of the tasks in SMT will result in a better understanding of these tasks from a theoretical perspective ."},{"claim_score":0.66234789,"evidence_score":-0.12081358,"claim":"our results may help in the design of effective heuristicsfor","text":"We also believe that our results may help in the design of effective heuristicsfor some of these tasks ."},{"claim_score":-0.44917468,"evidence_score":-0.20135859,"text":"A theoretical analysis of the commonly employed heuristics will also be of interest.An open question in SMT is whether there exists closed form expressions ( whose representation is polynomial in the size of the input ) for P ( f | e ) and the counts in the EM iterations for models 3-5 ( Brown et al 1993 For models 1-2 , closed formexpressions exist for P ( f | e ) and the counts in theEM iterations for models 3-5 ."},{"claim_score":-0.39821592,"evidence":"Our results showthat there can not exist a closed form expression ( whose representation is polynomial in the size of the input ) for P ( f | e ) and the counts in the EMiterations for Models 3-5 unless P NP","evidence_score":0.1003795,"text":"Our results showthat there can not exist a closed form expression ( whose representation is polynomial in the size of the input ) for P ( f | e ) and the counts in the EMiterations for Models 3-5 unless P NP"}]}