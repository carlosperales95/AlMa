{"document":[{"claim_score":-0.66179546,"evidence_score":-0.34332571,"text":"This paper describes the phrase-based SMT systems developed for our participation in the WMT11 Shared Translation Task.Translations for EnglishGerman andEnglishFrench were generated using aphrase-based translation system which isextended by additional models such as bilingual and fine-grained POS language models , POS-based reordering , lattice phrase extraction and discriminative word alignment ."},{"claim_score":-1.0834739,"evidence_score":-0.10400752,"text":"Furthermore , we present a special filtering method for the English-French Giga corpus and the phrase scoring step in the training is parallelized ."},{"claim_score":-2.5524784,"evidence_score":-0.19013039,"text":"In this paper we describe our systems for the EMNLP 2011 Sixth Workshop on Statistical Machine Translation ."},{"claim_score":-2.0825789,"evidence":"We participated in the Shared Translation Task and submitted translations for EnglishGerman and EnglishFrench .","evidence_score":0.33081515,"text":"We participated in the Shared Translation Task and submitted translations for EnglishGerman and EnglishFrench ."},{"claim_score":-0.86991387,"evidence_score":-0.43097123,"text":"We use a phrase-based decoder that can use lattices as input and developed several models that extend the standard log-linear model combination of phrase-based MT. These include advanced reordering models and corresponding adaptations to the phrase extraction process as well as extension to the translation and language model in form of discriminative word alignment and a bilingual language model to extend source word context ."},{"claim_score":-0.73794439,"evidence_score":-0.07147864,"text":"For English-German , language models based on fine-grained part-of-speech tags were used to address the difficult target language generation due to the rich morphology of German.We also present a filtering method directly addressing the problems of web-crawled corpora , which enabled us to make use of the French-English Giga corpus ."},{"claim_score":-1.0820175,"evidence_score":-0.68560905,"text":"Another novelty in our systems this year is the parallel phrase scoring method that reduces the time needed for training which is especially convenient for such big corpora as the Giga corpus ."},{"claim_score":-1.68692,"evidence":"We have presented the systems for our participation in the WMT 2011 Evaluation for EnglishGerman and EnglishFrench .","evidence_score":0.20401773,"text":"We have presented the systems for our participation in the WMT 2011 Evaluation for EnglishGerman and EnglishFrench ."},{"claim_score":-1.9038028,"evidence_score":-0.45322334,"text":"For EnglishFrench , a special filtering method for web-crawled data was developed ."},{"claim_score":-0.56336684,"evidence":"In addition , a parallel phrase scoring technique was implemented that could speed up the MT training process tremendously .","evidence_score":0.22910382,"text":"In addition , a parallel phrase scoring technique was implemented that could speed up the MT training process tremendously ."},{"claim_score":-2.3097941,"evidence_score":-0.4366673,"text":"Using these two features , we were able to integrate the huge amounts of data available in the Giga corpus into our systems translating between English and French ."},{"claim_score":-0.67140154,"evidence":"We applied POS-based reordering to improve our translations in all directions , using short-range reordering for EnglishFrench and long-range reordering for EnglishGerman .","evidence_score":0.28147204,"text":"We applied POS-based reordering to improve our translations in all directions , using short-range reordering for EnglishFrench and long-range reordering for EnglishGerman ."},{"claim_score":-0.90421127,"evidence_score":-0.49752901,"text":"For GermanEnglish , reordering also the training corpus lead tofurther improvements of the translation quality ."},{"claim_score":-1.5143254,"evidence":"A Discriminative Word Alignment Model led to an increase in BLEU for English-German .","evidence_score":0.040337578,"text":"A Discriminative Word Alignment Model led to an increase in BLEU for English-German ."},{"claim_score":-2.2228637,"evidence_score":-0.41971392,"text":"For this direction we also tried fine-grained POS language models of different n-gram lengths ."},{"claim_score":-0.48118623,"evidence_score":-0.81558289,"text":"The best translations could be obtained by using 4-grams ."},{"claim_score":-0.55223161,"evidence_score":-0.31313681,"text":"For nearly all experiments , a bilingual language model was applied that expands the context of source words that can be considered during decoding ."},{"claim_score":-0.37585275,"evidence_score":-0.24352093,"text":"The improvements range from 0.1 to 0.4 in BLEU score"}]}