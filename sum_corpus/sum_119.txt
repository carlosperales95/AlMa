Abstract
 Humans and animals learn much better when the examples are not randomly presented but organized in a meaningful order which illustrates gradually more concepts, and gradually more complex ones. Here, we formalize such training strategies in the context of machine learning, and call them “curriculum learning”. In the context of recent research studying the difficulty of training in the presence of non-convex training criteria (for deep deterministic and stochastic neural networks), we explore curriculum learning in various set-ups. The experiments show that significant improvements in generalization can be achieved. We hypothesize that curriculum learning has both an effect on the speed of convergence of the training process to a minimum and, in the case of non-convex criteria, on the quality of the local minima obtained: curriculum learning can be seen as a particular form of continuation method (a general strategy for global optimization of non-convex functions).

Discussion and Future Work
 We started with the following question left from previous cognitive science research (Elman, 1993; Rohde & Plaut, 1999): can machine learning algorithms benefit from a curriculum strategy? Our experimental results in many different settings bring evidence towards a positive answer to that question. It is plausible that some curriculum strategies work better than others, that some are actually useless for some tasks (as in Rohde and Plaut (1999)), and that better results could be obtained on our data sets with more appropriate curriculum strategies. After all, the art of teaching is difficult and humans do not agree among themselves about the order in which concepts should be introduced to pupils. From the machine learning point of view, once the success of some curriculum strategies has been established, the important questions are: why? and how? This is important to help us devise better curriculum strategies and automate that process to some extent. We proposed a number of hypotheses to explain the potential advantages of a curriculum strategy: • faster training in the online setting (i.e. faster both from an optimization and statistical point of view) because the learner wastes less time with noisy or harder to predict examples (when it is not ready to incorporate them), • guiding training towards better regions in parameter space, i.e. into basins of attraction (local minima) of the descent procedure associated with better generalization: a curriculum can be seen as a particular continuation method. Faster convergence with a curriculum was already observed in (Krueger & Dayan, 2009). However, unlike in our experiments where capacity is fixed throughout the curriculum, they found that compared to using no curriculum, worse results were obtained with fixed neural resources. The reasons for these differences remain to be clarified. In both cases, though, an appropriate curriculum strategy acts to help the training process (faster convergence to better solutions), and we even find that it regularizes, giving rise to lower generalization error for the same training error. This is like in the case of unsupervised pre-training (Erhan et al., 2009), and again it remains to be clarified why  one would expect improved generalization, for both curriculum and unsupervised pre-training procedures. The way we have defined curriculum strategies leaves a lot to be defined by the teacher. It would be nice to understand general principles that make some curriculum strategies work better than others, and this clearly should be the subject of future work on curriculum learning. In particular, to reap the advantages of a curriculum strategy while minimizing the amount of human (teacher) effort involved, it is natural to consider a form of active selection of examples similar to what humans (and in particular children) do. At any point during the “education” of a learner, some examples can be considered “too easy” (not helping much to improve the current model), while some examples can be considered “too difficult” (no small change in the model would allow to capture these examples). It would be advantageous for a learner to focus on “interesting” examples, which would be standing near the frontier of the learner’s knowledge and abilities, neither too easy nor too hard. Such an approach could be used to at least automate the pace at which a learner would move along a predefined curriculum. In the experiments we performed, that pace was fixed arbitrarily. This kind of strategy is clearly connected to active learning (Cohn et al., 1995), but with a view that is different from the standard one: instead of focusing on the examples near the decision surface to quickly infer its location, we think of the set of examples that the learner succeeds to capture and gradually expand that set by preferentially adding examples near its border. Curriculum learning is related to boosting algorithms, in that difficult examples are gradually emphasized. However, a curriculum starts with a focus on the easier examples, rather than a uniform distribution over the training set. Furthermore, from the point of view of the boosted weighted sum of weak learners, there is no change in the training criterion: the change is only from the point of view of the next weak learner. As far as the boosted sum is concerned, we are following a functional gradient on the same training criterion (the sum of exponentiated margins). Curriculum strategies are also connected to transfer (or multi-task) learning and lifelong learning (Thrun, 1996). Curriculum learning strategies can be seen as a special form of transfer learning where the initial tasks are used to guide the learner so that it will perform better on the final task. Whereas the traditional motivation for multitask learning is to improve generalization by sharing across tasks, curriculum learning adds the notion of guiding the optimization process, either to converge faster, or more importantly, to guide the learner towards better local minima.  Curriculum Learning  Acknowledgements: The authors thank NSERC, CIFAR, and MITACS for support.  References Allgower, E. L.
